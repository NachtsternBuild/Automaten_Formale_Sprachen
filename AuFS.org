#+title: Automaten und Formale Sprachen

#+author: Peter
Kossek[[mailto:e0030414@edu.dhsn.de][e0030414@edu.dhsn.de]]

Organisatorisches

- Vorlesungen

- Übungen

- Fragen jeder Art

- besondere Bedürfnisse

*** Literatur
:PROPERTIES:
:CUSTOM_ID: literatur
:END:

- Script zur Vorlesung\\
  [[https://github.com/bluepoke/Automaten_Formale_Sprachen/releases/latest]]

- Grundlage der Vorlesung

  - Schöning, U.: /Logik für Informatiker/

  - Schöning, U.: /Theoretische Informatik - kurz gefasst/

- Weitere Literatur

  - Vossen, G.; Witt, K. U.: /Grundlagen der Theoretischen Informatik
    mit Anwendungen/

  - Hollas, B.: /Grundkurs Theoretische Informatik/

  - Erk, K.; Priese, L.: /Theoretische Informatik/

*** Gliederung
:PROPERTIES:
:CUSTOM_ID: gliederung
:END:

Wozu brauche ich das?

\[L(A)=\left\{w \in \Sigma^* \mid w=0 \lor w=x00, x\in \Sigma^*\right\}\]

\[\begin{aligned}
		\delta = \{&(s_0, a, s_1, x, R), (s_0, x, s_0, x, R), (s_0, \#, s_f, \#, N),\\
		&(s_1, x, s_1, x, R), (s_1, a, s_1, a, R), (s_1, b, s_2, x, R),\\
		&(s_2, b, s_2, b, R), (s_2, \#, s_3, \#, L), (s_3, b, s_3, b, L),\\
		&(s_3, x, s_3, x, L), (s_3, a, s_3, a, L), (s_3, \#, s_0, \#, R)\}
	
\end{aligned}\]

* Aussagenlogik
:PROPERTIES:
:CUSTOM_ID: aussagenlogik
:END:
** Aussagenlogische Formeln
:PROPERTIES:
:CUSTOM_ID: aussagenlogische-formeln
:END:

Syntax

- /Aussage:/ Satz, der entweder wahr (\(w\)) oder falsch (\(f\)) ist;
  Aussagenvariable \(A\); Wahrheitswert \(w(A)\)

- /Syntax:/ Induktive Definition korrekt gebildeter aussagenlogischer
  Formeln F über Variablenmenge \(V=\{A, B, \ldots\}\):

  - Die Booleschen Wahrheitswerte \(w\) und \(f\) sind Formeln

  - Jede Variable aus \(V\) ist eine Formel: /Atome/

  - Negation: \(\neg F\) ist eine Formel

  - Konjunktion: \((F_1 \land F_2)\) ist eine Formel

  - Disjunktion: \((F_1 \lor F_2)\) ist eine Formel

  - Implikation: \((F_1 \rightarrow F_2)\) ist eine Formel

  - Äquivalenz: \((F_1 \leftrightarrow F_2)\) ist eine Formel

  - andere Verknüpfungen bilden keine Formel

Präzedenzregeln Vereinbarung zur Reduzierung von Klammern

- Bindung (analog "Punkt vor Strich"-Rechnung)

  - \(\neg\) bindet stärker als \(\land\)

  - \(\land\) bindet stärker als \(\lor\)

  - \(\lor\) bindet stärker als \(\rightarrow\) und \(\leftrightarrow\)

- Operatoren gleicher Stärke: Auswertung linksassoziativ; z.B.\\
  \((A \lor B \lor C)\) steht für \(((A \lor B) \lor C)\)

- äußere Klammer weglassen:
  \((((A \lor B) \rightarrow C) \land B) \mapsto (A \lor B \rightarrow C) \land B\)

Semantik aussagenlogischen Formeln wird eine Bedeutung zugeordnet

- Def. Belegung (Interpretation) \(I: V \rightarrow \{f, w\}\)\\
  den Atomen wird jeweils ein konkreter Wahrheitswert zugeordnet

- schrittweise (über die Bewertung von Teilformeln) lassen sich dann
  zusammengesetzte Formeln bewerten:

  - \(I(\neg F)=w\) falls \(I(F)=f\), sonst \(I(\neg F)=f\)

  - \(I(F \land G)=w\) falls \(I(F)=w\) und \(I(G)=w\), sonst
    \(I(F \land G)=f\)

  - \(I(F \lor G)=w\) falls \(I(F)=w\) oder \(I(G)=w\), sonst
    \(I(F \lor G)=f\)

  - \(I(F \rightarrow G)=w\) falls \(I(F)=f\) oder \(I(G)=w\), sonst
    \(I(F \rightarrow G)=f\)

  - \(I(F \leftrightarrow G)=w\) falls \(I(F)=I(G)\), sonst
    \(I(F \leftrightarrow G)=f\)

Semantik: Darstellung per Wahrheitstafel Wahrheitstafel enthält
zeilenweise alle möglichen Belegungen

| \(A\) | \(B\) | \(\neg A\) | \(A \land B\) | \(A \lor B\) | \(A \rightarrow B\) | \(A \leftrightarrow B\) |
|-------+-------+------------+---------------+--------------+---------------------+-------------------------|
| f     | f     | w          | f             | f            | w                   | w                       |
| f     | w     | w          | f             | w            | w                   | f                       |
| w     | f     | f          | f             | w            | f                   | f                       |
| w     | w     | f          | w             | w            | w                   | w                       |
#+caption: Wahrheitstafel der Grundoperationen

semantische Äquivalenz \(F_1 \equiv F_2\): \(F_1\) und \(F_2\) haben
gleichen Wahrheitswerteverlauf; z.B.\\
\(A \rightarrow B \equiv \neg A \lor B\)\\
\(A \leftrightarrow B \equiv (A \rightarrow B) \land (B \rightarrow A)\)

Erfüllbarkeit, Tautologie, Kontradiktion

- Sei \(F\) eine Formel und \(I\) eine Belegung. Falls \(I\) für alle in
  \(F\) vorkommenden Atome definiert ist, so heißt \(I\) _zu \(F\)
  passend_

- Falls \(I\) zu \(F\) passend ist, und es gilt \(I(F)=w\), dann heißt
  \(I\) _Modell für \(F\)_; Schreibweise: \(I \models F\)

- \(F\) heißt _erfüllbar_, falls \(F\) mindestens ein Modell besitzt;
  sonst heißt \(F\) _unerfüllbar_ (Kontradiktion; Schreibweise
  \(F\bot\))

- \(F\) heißt gültig bzw. _Tautologie_, falls jede zu \(F\) passende
  Belegung \(I\) ein Modell für \(F\) ist; Schreibweise \(\models F\)
  oder \(F\top\)\\
  Beispiel: \((A \land B) \rightarrow A\)

- es gilt: \(F\) ist Tautologie gdw. \(\neg F\) ist Kontradiktion

Äquivalenz aussagenlogischer Formeln

- Zwei Formeln \(F\) und \(G\) heißen semantisch äquivalent
  (\(F \equiv G\)), falls für alle Belegungen \(I\) gilt: \(I(F)=I(G)\)

- Äquivalenz kann bewiesen (oder widerlegt) werden durch Aufstellen der
  jeweiligen Wahrheitstafeln

- Beispiele

  - \(A \rightarrow B \equiv \neg A \lor B\)

  - \(A \leftrightarrow B \equiv (A \land B) \lor (\neg A \land \neg B) \equiv (A \rightarrow B) \land (B \rightarrow A)\)

- Ersetzbarkeitstheorem:\\
  enthält eine Formel \(F\) eine Teilformel \(G\) und wird \(G\) durch
  eine äquivalente Formel ersetzt, so entsteht eine zu \(F\) äquivalente
  Formel

Äquivalenzen als Rechenregeln

- Idempotenz

  - \((A \land A) \equiv A\)

  - \((A \lor A) \equiv A\)

- Kommutativgesetz

  - \((A \land B) \equiv (B \land A)\)

  - \((A \lor B) \equiv (B \lor A)\)

- Assoziativgesetz

  - \((A \land (B \land C)) \equiv ((A \land B) \land C)\)

  - \((A \lor (B \lor C)) \equiv ((A \lor B) \lor C)\)

- Distributivgesetz

  - \((A \land (B \lor C)) \equiv ((A \land B) \lor (A \land C))\)

  - \((A \lor (B \land C)) \equiv ((A \lor B) \land (A \lor C))\)

Äquivalenzen als Rechenregeln (Fortsetzung)

- Absorptionsgesetz

  - \((A \land (A \lor B)) \equiv A\)

  - \((A \lor (A \land B)) \equiv A\)

- Doppelnegation

  - \(\neg \neg A \equiv A\)

- deMorgansche Regeln

  - \(\neg (A \land B) \equiv (\neg A \lor \neg B)\)

  - \(\neg (A \lor B) \equiv (\neg A \land \neg B)\)

- Tautologieregeln: sei \(A\) Tautologie; \(A\top\) bzw. \(\models A\)
  bzw. \(A \equiv w\)

  - \((A \lor B) \equiv (w \lor B) \equiv w \equiv A\);
    \((A \land B) \equiv (w \land B) \equiv B\)

- Kontradiktionsregeln: sei \(A\) Kontradiktion; \(A\bot\) bzw.
  \(A \equiv f\)

  - \((A \lor B) \equiv (f \lor B) \equiv B\);
    \((A \land B) \equiv (f \land B) \equiv f \equiv A\)

Beispiel: direkter Beweis der Gültigkeit einer Formel\\
(als Alternative zur Wahrheitstafel)

\[\begin{aligned}
				F &=& (A \land (A \rightarrow B)) \rightarrow B\\
				  &\equiv& \neg (A \land (A \rightarrow B)) \lor B\\
				  &\equiv& \neg (A \land (\neg A \lor B)) \lor B\\
				  &\equiv& \neg A \lor \neg(\neg A \lor B) \lor B\\
				  &\equiv& \neg A \lor (A \land \neg B) \lor B\\
				  &\equiv& \neg A \lor (A \lor B) \land (\neg B \lor B)\\
				  &\equiv& \neg A \lor (A \lor B) \land w\\
				  &\equiv& \neg A \lor A \lor B\\
				  &\equiv& w \lor B\\
				  &\equiv& w
		
\end{aligned}\]

| \(A\) | \(B\) | \(A \rightarrow B\) | \(A \land (A \rightarrow B)\) | \(F\) |
|-------+-------+---------------------+-------------------------------+-------|
| f     | f     | w                   | f                             | w     |
| f     | w     | w                   | f                             | w     |
| w     | f     | f                   | f                             | w     |
| w     | w     | w                   | w                             | w     |

Normalformen

- /Literal:/ Aussagenvariable \(A\) ("positives Literal") oder negierte
  Aussagenvariable \(\neg A\) ("negatives Literal")

- /Negationsnormalform (NNF)/: Formel \(F\) ist in NNF, falls
  \(\rightarrow\) und \(\leftrightarrow\) aufgelöst sind und alle
  Negationszeichen \(\neg\) unmittelbar vor einer Aussagenvariable
  stehen.\\
  beachte: NNF ist nicht eindeutig

- /Monom:/ Konjunktion von Literalen, d.h. Formel der Art\\
  \(\bigwedge_iL_i=L_1\land L_2\land\ldots\land L_k\)

- /Klausel:/ Disjunktion von Literalen, d.h. Formel der Art\\
  \(\bigvee_iL_i=L_1\lor L_2\lor\ldots\lor L_k\)

Disjunktive Normalform (DNF) und Konjunktive Normalform (KNF)

- Disjunktive Normalform /DNF:/ Disjunktion von Konjunktionen
  (Monomen)\\
  \(F=\bigvee_i\left(\bigwedge_jL_{ij}\right)\)

- Konjunktive Normalform /KNF:/ Konjunktion von Disjunktionen
  (Klauseln)\\
  \(F=\bigwedge_i\left(\bigvee_jL_{ij}\right)\)

- Für jede Formel existiert eine äquivalente Formel in KNF und eine
  äquivalente Formel in DNF

  - Erzeuge NNF \(\mapsto\) DNF bzw. KNF\\
    DNF: ersetze Ausdrücke der Art \((F \land (G \lor H))\) durch
    \((F \land G) \lor (F \land H)\) solange solche Teilformen
    existieren\\
    KNF: ersetze Ausdrücke der Art \((F \lor (G \land H))\) durch
    \((F \lor G) \land (F \lor H)\) solange solche Teilformeln
    existieren

Konstruktion kanonische DNF/KNF aus Wahrheitstafel

- /Kanonische/ DNF bzw. KNF: jede Aussagenvariable kommt in jedem Monom
  bzw. jeder Klausel genau einmal vor (positiv oder negativ)

- Kanonische NF lassen sich aus der Wahrheitstafel der Formel ablesen

  - Kanonische DNF (KDNF)

    - Je ein Monom für jede Belegung mit Wahrheitswert \(w\)

    - Setze \(L_j=A_j\), falls \(w(A_j)=w\), \(L_j=\neg A_j\) sonst

  - Kanonische KNF (KKNF)

    - Je eine Klausel für jede Belegung mit Wahrheitswert \(f\)

    - Setze \(L_j=\neg A_j\), falls \(w(A_j)=w\), \(L_j=A_j\) sonst

- Übungsbeispiel (KNF, aber nicht kanonisch)\\
  \(F=\neg B \land (A \lor \neg C)\)

Beispiel: Konstruktion von KDNF und KKNF aus Wahrheitstafel

#+begin_center
| A | B | C | F |
|---+---+---+---|
| 0 | 0 | 0 | 1 |
| 0 | 0 | 1 | 0 |
| 0 | 1 | 0 | 0 |
| 0 | 1 | 1 | 0 |
| 1 | 0 | 0 | 1 |
| 1 | 0 | 1 | 1 |
| 1 | 1 | 0 | 0 |
| 1 | 1 | 1 | 0 |

#+end_center

- Werte für F=1 auslesen
  \[(\neg A \land \neg B \land \neg C) \lor (A \land \neg B \land \neg C) \lor (A \land \neg B \land C)\]

- Werte für F=0 auslesen und Literale negieren \[\begin{aligned}
  				&(A \lor B \lor \neg C) \land (A \lor \neg B \lor C) \land \\
  				&(A \lor \neg B \lor \neg C) \land (\neg A \lor \neg B \lor C) \land (\neg A \lor \neg B \lor \neg C)
  			
  \end{aligned}\]

- Minimierung der KKNF und KDNF durch Karnaugh-Veitch-Diagramm möglich
  (dann aber i.d.R. nicht mehr kanonisch)

Beispiel: Karnaugh-Tafel

Karnaugh-Tafel für \(F=\neg B \land (A \lor \neg C)\)

#+begin_center
|            | \(AB\) | \(\neg A B\) | \(\neg A \neg B\) | \(A \neg B\) |
|------------+--------+--------------+-------------------+--------------|
| \(C\)      | 0      | 0            | 0                 | 1            |
| \(\neg C\) | 0      | 0            | 1                 | 1            |

#+end_center

Abgeleitete Formeln:

- Einsen zu Blöcken (Größe \(2^n\)) und die Variablen im Block
  weglassen, die sowohl positiv als auch negativ vertreten sind.
  Variablen mit Konjunktion verknüpfen, Blöcke mit Disjunktion:\\
  \((\neg B \land \neg C) \lor (A \land \neg B)\)

- Wie DNF, aber: Nullen zu Blöcken, Variablen negieren, Verknüpfungen
  umkehren\\
  \((\neg B) \land (A \lor \neg C)\)

Aussagenlogische Formeln in Java

- Datentyp =boolean=\\
  =p,q; //zulässige Werte: true, false=

- Logische Verküpfungen\\

  UND: =&&=\\
  ODER: =||=\\
  NICHT: =!=

- Beispiel\\
  =boolean p,q;=\\
  =int x = 8;=\\
  =p = false;=\\
  =q = x == 10; // false=\\
  =p = (p || q) && x < 10; // false=

- Vorrangregeln: =!= bindet stärker als =&&= bindet stärker als =||=

** Mengen/Relationen
:PROPERTIES:
:CUSTOM_ID: mengenrelationen
:END:

Exkurs: Mengen

- /Menge:/ Zusammenfassung unterschiedlicher Objekte (Elemente) zu einer
  Einheit

- /Bezeichner:/
  \(M=\left\{x \in G \mid \textrm{Bedingung}_1, \textrm{Bedingung}_2, \ldots \right\}\);
  \(G\): Grundmenge

- Beispiel:
  \(M=\left\{n \in \mathbb{N} \mid n^2-3n+2=0 \right\}=\left\{1,2\right\}\)

- /Leere Menge:/ \(\varnothing=\left\{{}\right\}\)

- /Teilmengen:/ \(A \subseteq B\) gdw. \(x \in A \rightarrow x \in B\)
  für alle \(x \in G\)

- /Gleichheit von Mengen:/ \(A=B\) gdw.
  \(A \subseteq B \land B \subseteq A\)\\
  z.B. \(A = \left\{a, b, a\right\}, B = \left\{b, a\right\}\) es gilt:
  \(A = B\)

- /Mächtigkeit (endlicher) Mengen:/\\
  \(|M|=\) Anzahl verschiedener Elemente von \(M\); z.B.
  \(|\left\{a, b, a\right\}|=2\)

Mengenverknüpfungen

- Durchschnitt:
  \(A \cap B = \left\{x \mid x \in A \land x \in B\right\}\)

- Vereinigung: \(A \cup B = \left\{x \mid x \in A \lor x \in B\right\}\)

- Differenz:
  \(A \setminus B = \left\{x \mid x \in A \land x \notin B\right\}\)\\
  insbesondere: Komplement \(A'= \bar{A} = G \setminus A\)

- es gelten Kommutativ-, Assoziativ- und Distributivgesetze,
  insbesondere\\
  \(A \cap \left(B \cup C\right) = \left(A \cap B\right) \cup \left(A \cap C\right)\)\\
  \(A \cup \left(B \cap C\right) = \left(A \cup B\right) \cap \left(A \cup C\right)\)

- Potenzmenge \(P(M) =\) Menge aller Teilmengen von M, z.B.\\
  \(M=\left\{a, b, c\right\}\)\\
  \(P(M)=\left\{\varnothing, \{a\}, \{b\}, \{c\}, \{a,b\}, \{a,c\}, \{b,c\}, \{a,b,c\}\right\}\)\\
  es gilt: \(|P(M)|=2^{|M|}\)

Relationen Begriffsbestimmungen

- Kartesisches Produkt zweier Mengen \(A, B\)\\
  Menge aller geordneten Paare
  \((a,b): A \times B = \left\{(a,b) \mid a \in A, b \in B\right\}\)

- Binäre Relation \(R\) zwischen \(A\) und \(B\)\\
  \(R \subseteq A \times B\), Sprechweise: \((a,b) \in R \Rightarrow a\)
  und \(b\) stehen in Relation \(R\)

- Darstellungen: Tabelle, Pfeildiagramm

- Produkt (Komposition) \(R_1 \circ R_2\)\\
  sei \(R_1 \subseteq A \times B, R_2 \subseteq B \times C\)\\
  \(R_1 \circ R_2 = \left\{(a,c) \mid \textrm{es ex. ein } b \in B \textrm{ mit } (a,b) \in R_1, (b,c) \in R_2\right\}\)

- Inverse Relation \(R^{-1}\)\\
  sei
  \(R \subseteq A \times B \Rightarrow R^{-1}\subseteq B \times A\)\\
  \(R^{-1}=(b,a) \mid a \in A, b \in B, (a,b) \in R\)

Binäre Relationen /in einer/ Menge \(M: R \subset M \times M\)

- Bezeichnung: es gelte \(a,b,c \in M\)

- /Identität \(I\):/ \(I=\left\{(a,a) \mid a \in M\right\}\)

- \(R\) heißt /reflexiv/ gdw. \(I \subseteq R\)

- \(R\) heißt /symmetrisch/ gdw. \((a,b) \in R \rightarrow (b,a) \in R\)

- \(R\) heißt /asymmetrisch/ gdw.
  \((a,b) \in R \rightarrow (b,a) \notin R\)

- \(R\) heißt /antisymmetrisch/ gdw.
  \((a,b) \in R \land (b,a) \in R \rightarrow a = b\)

- \(R\) heißt /transitiv/ gdw.
  \(((a,b) \in R \land (b,c) \in R) \rightarrow (a,c) \in R\)

- /Transitive Hülle/ \(T\) von \(R\)\\
  \(T=\{(a,b) \mid (a,b) \in R, \textrm{ oder: es gibt } c_0, c_1, \ldots, c_m \in M\)\\
  \(\textrm{mit } (a,c_0) \in R, (c_0, c_1) \in R, \ldots, (c_m,b) \in R\}\)

Beispiel: Reflexivität

- Reflexivität: Jedes Element der Relation steht mit sich selbst in
  Relation.

  - "\(=\)": \(a=a\)

  - "Studenten mit gleicher Punktzahl in einer Klausur": Jeder Student
    hat die gleiche Punktzahl wie er selbst.

  - Darstellung als Tabelle und Graph:\\

    ​|Y|Y|Y|Y|Y| & A & B & C & D\\
    A & X & & &\\
    B & & X & &\\
    C & & & X &\\
    D & & & & X\\

Beispiel: Symmetrie

- Symmetrie: zwei Elemente, die in Relation stehen, stehen umgekehrt
  auch in Relation.

  - "\(=\)": \(a=b\quad\rightarrow\quad b=a\)

  - "Geschwister": Anna ist Geschwister von Charlie. Dann ist Charlie
    auch Geschwister von Anna.

  - Darstellung als Tabelle und Graph:\\

    ​|Y|Y|Y|Y|Y| & A & B & C & D\\
    A & & & X &\\
    B & & & & X\\
    C & X & & &\\
    D & & X & &\\

Beispiel: Transitivität

- Transitivität: Wenn ein Element mit einem anderen in Relation steht,
  und dieses wiederum mit einem dritten, so steht auch das erste mit dem
  dritten Element in Relation.

  - "\(=\)": \(a=b \land b=d \rightarrow a=d\)

  - "Vorfahren": Albert ist Vorfahr von Brunhilde. Brunhilde ist Vorfahr
    von Diana. Dann ist Albert auch Vorfahr von Diana.

  - Darstellung als Graph (in Tabelle nicht gut zu sehen):\\

Äquivalenzrelationen

- Definition: \(R\) in \(M\) heißt Äquivalenzrelation in \(M\) gdw.
  \(R\) ist reflexiv, symmetrisch und transitiv

- Äquivalenzklassen: \(R[x]=\{y \mid (x,y) \in R\}\) heißt
  Äquivalenzklasse von \(x\) bezüglich \(R\);\\
  es gilt: zwei Äquivalenzklassen \(R[x], R[y]\) sind entweder identisch
  oder disjunkt

- Beispiel (Zahlentheorie): Kongruenz\\
  zwei ganze Zahlen \(a,b\) heißen kongruent bzgl. \(m \in \mathbb{N}\)
  gdw. sie haben bei Division durch \(m\) den gleichen Rest\\
  Schreibweise: \(a \equiv b\ (\mathrm{mod}\ m)\)\\
  Rechenregeln: sei
  \(a \equiv a'\ (\mathrm{mod}\ m), b \equiv b'\ (\mathrm{mod}\ m)\)\\
  \(a+b\equiv a'+b'\ (\mathrm{mod}\ m), a \cdot b \equiv a' \cdot b'\ (\mathrm{mod}\ m)\)

Abbildungen

- Sei \(R\) eine Relation zwischen den Mengen \(A,B\)

  - \(R\) heißt /linkseindeutig/ gdw.
    \((a_1,b)\in R\land (a_2,b)\in R \rightarrow a_1=a_2\)

  - \(R\) heißt /rechtseindeutig/ gdw.
    \((a,b_1)\in R\land (a,b_2)\in R \rightarrow b_1=b_2\)

- Eine /Abbildung/ \(f\) von \(A\) /in/ die Menge \(B\) entspricht einer
  rechtseindeutigen Relation \(F\) zwischen \(A\) und \(B\), für die es
  zu jedem \(a\in A\) ein \(b\in B\) gibt mit \((a,b) \in F\)\\
  Bezeichnung: \(f: A \rightarrow B\) bzw. \(b=f(a)\)

- Eine Abbildung \(f\) heißt /surjektiv/ (Abbildung /auf/ \(B\)), wenn
  es zu jedem \(b\in B\) ein \(a\in A\) gibt mit \(b=f(a)\).\\
  Schreibweise: \(B = f(A)\)

- Eine Abbildung \(f\) heißt /injektiv/ (eineindeutig), wenn die
  zugehörige Relation \(F\) auch linkseindeutig ist

- Eine Abbildung \(f\) heißt /bijektiv/, wenn sie surjektiv und injektiv
  ist. Die inverse Relation \(F^{-1}\) erklärt dann die inverse
  Abbildung \(a = f^{-1}(b)\) bzw. \(A=f^{-1}(B)\)

** Boolesche Rechenregeln
:PROPERTIES:
:CUSTOM_ID: boolesche-rechenregeln
:END:

Boolesche Algebra: Rechenregeln

/Abstrakte Definition/\\
Boolesche Algebra \((B, +, \times, \kappa)\)

- \(B\): Grundmenge, enthält insbesondere 0 und 1

- \(+\) und \(\times\): zweistellige Operationen auf \(B\)

- \(\kappa\): einstellige Operation auf \(B\) (Komplement)

- dazu gelten die folgenden vier Rechengesetze \((a,b,c\in B)\)

/vorausgesetzte Rechenregeln/\\

- Kommutativgesetze\\
  \(a+b=b+a\), \(a \times b=b \times a\)

- Distributivgesetze\\
  \(a \times (b + c) = (a \times b) + (a\times c)\)\\
  \(a + (b \times c) = (a + b) \times (a + c)\)\\

- Neutralitätsgesetze\\
  \(a \times 1 = a\), \(a + 0 = a\)

- Komplementgesetze \(a + \kappa(a) = 1\), \(a \times \kappa(a) = 0\)

Beispiele

- Potenzmenge; \(B=P(M)\)\\
  \(+:\cup\), \(\times:\cap\), \(\kappa(A):M\setminus A\),
  \(0:\varnothing\), \(1:M\)

- \(B\): Menge der n-stelligen aussagenlogischen Formeln\\
  (gebildet aus maximal n verschiedenen Aussagenvariablen, zzgl. \(w\),
  \(f\))\\
  \(+:\lor\), \(\times:\land\), \(\kappa:\neg\), \(0:f\), \(1:w\)

- Schaltfunktionen-Algebra

Abgeleitete Rechenregeln für Boolesche Ausdrücke

- Dualitätsprinzip der Booleschen Algebra:\\
  zu jeder Rechenregel existiert eine zweite (duale) Rechenregel, die
  durch Vertauschung \(+\) mit \(\times\) und \(0\) mit \(1\) entsteht

- Regeln\\

  ̄̄ Idempotenz: \(a+a=a\) \(a\times a = a\)\\
  Dominanzgesetz: \(a+1=1\) \(a\times 0 = 0\)\\
  Absorptionsgesetz: \(a+(a\times b) = a\) \(a \times (a + b) = a\)\\
  Gleichungsvereinfachung: aus \(b+a=c+a\) und
  \(b+\kappa(a)=c+\kappa(a)\)\\
  folgt \(b=c\)\\
  Assoziativgesetz: \(a+(b+c)=(a+b)+c\)\\
  \(a\times (b\times c)=(a\times b)\times c\)\\
  De Morgansche Gesetze: \(\kappa(a+b) = \kappa(a) \times \kappa(b)\)\\
  \(\kappa(a\times b) = \kappa(a) + \kappa(b)\)

Beweisbeispiele

\[\begin{aligned}
			a+a&=a\\
			a+a&=(a+a)\times 1\\
			   &=(a+a)\times (a+\kappa(a))\\
			   &=a+(a\times \kappa(a))\\
			   &=a+0\\
			   &=a
		
\end{aligned}\] \[\begin{aligned}
			a+1&=1\\
			a+1&=(a+1)\times 1\\
			&=(a+1)\times (a+\kappa(a))\\
			&=a+(1\times \kappa(a))\\
			&=a+\kappa(a)\\
			&=1
		
\end{aligned}\] \[\begin{aligned}
			a+(a\times b)&=a\\
			a+(a\times b)&=(a\times 1)+(a\times b)\\
			&=a\times (1+b)\\
			&=a\times 1\\
			&=a\\
		
\end{aligned}\]

Beispiel: Schaltfunktionen-Algebra

- Jeder n-stellige Boolesche Ausdruck stellt eine n-stellige
  Schaltfunktion \(f(x_1,\ldots,x_n)\), d.h.
  \(f:\left\{0,1\right\}^n\rightarrow\left\{0,1\right\}\) dar

- Bezeichnungen an Stelle
  \(f,w,\lor,\land,\neg:0,1,+,\cdot,\textrm{Überstrich}\)

- Schaltfunktionen-Algebra:\\
  \(B=\) Menge aller n-stelligen Schaltfunktionen\\
  \(0:f\equiv 0\)\\
  \(1:f\equiv 1\)\\
  \(+:\mathrm{Max}[f,g](x_1,\ldots,x_n)=\mathrm{max}\left\{f(x_1,\ldots,x_n),g(x_1,\ldots,x_n)\right\}\)
  (zeilenweise)\\
  \(\cdot:\mathrm{Min}[f,g](x_1,\ldots,x_n)=\mathrm{min}\left\{f(x_1,\ldots,x_n),g(x_1,\ldots,x_n)\right\}\)
  (zeilenweise)\\
  \(\kappa : \kappa [f](x_1,\ldots,x_n)=1-f(x_1,\ldots,x_n)\)

Gatter IEC 60617-12

| AND  | \(Y=A\cdot B=AB\)                      | (0,0) node[and port] (gate) (gate.in 1) node[left](i1) A (gate.in 2) node[left](i2) B (gate.out) node[right](o) Y;  |
| OR   | \(Y=A+B\)                              | (0,0) node[or port] (gate) (gate.in 1) node[left](i1) A (gate.in 2) node[left](i2) B (gate.out) node[right](o) Y;   |
| NOT  | \(Y=\overline{A}\)                     | (0,0) node[not port] (gate) (gate.in 1) node[left](i1) A (gate.out) node[right](o) Y;                               |
| NAND | \(Y=\overline{AB}\)                    | (0,0) node[nand port] (gate) (gate.in 1) node[left](i1) A (gate.in 2) node[left](i2) B (gate.out) node[right](o) Y; |
| NOR  | \(Y=\overline{A+B}\)                   | (0,0) node[nor port] (gate) (gate.in 1) node[left](i1) A (gate.in 2) node[left](i2) B (gate.out) node[right](o) Y;  |
| XOR  | \(Y=A\overline{B}+\overline{A}B\)      | (0,0) node[xor port] (gate) (gate.in 1) node[left](i1) A (gate.in 2) node[left](i2) B (gate.out) node[right](o) Y;  |
| XNOR | \(Y=(\overline{A}+B)(A+\overline{B})\) | (0,0) node[xnor port] (gate) (gate.in 1) node[left](i1) A (gate.in 2) node[left](i2) B (gate.out) node[right](o) Y; |

Beispiele
\(y=((x_1\cdot x_2)\cdot(x_2+x_3))\cdot \overline{(x_2 + x_3)}\)\\

(0,0) coordinate[label=[below]\(x_1\)](x1) (0.5,0)
coordinate[label=[below]\(x_2\)](x2) (1,0)
coordinate[label=[below]\(x_3\)](x3)

(0,6) coordinate(x1End) (.5,6) coordinate(x2End) (1,6) coordinate(x3End)

(x1) -| (x1End) (x2) -| (x2End) (x3) -| (x3End)

(3,1) node[and port] (Aandx1x2) (3,3) node[or port] (Borx2x3) (5,2)
node[and port] (AandB) (3,5) node[nor port] (nor) (7,4) node[and port]
(andAll)

(Aandx1x2.in 1) to[short, -*] (x1 |- Aandx1x2.in 1) (Aandx1x2.in 2)
to[short, -*] (x2 |- Aandx1x2.in 2)

(Borx2x3.in 1) to[short, -*] (x2 |- Borx2x3.in 1) (Borx2x3.in 2)
to[short, -*] (x3 |- Borx2x3.in 2)

(nor.in 1) to[short, -*] (x2 |- nor.in 1) (nor.in 2) to[short, -*] (x3
​|- nor.in 2)

(Aandx1x2.out) -- (AandB.in 2) (Borx2x3.out) -- (AandB.in 1) (nor.out)
-- (andAll.in 1) (AandB.out) -- (andAll.in 2)

(andAll.out) node[right](y) y ;

George Boole (, )

- englischer Mathematiker (Autodidakt), Logiker und Philosoph

- Einbettung der Logik in die Mathematik

- wurde Mathematikprofessor, ohne selbst studiert zu haben

- Schriften:

  - /The Mathematical Analysis of Logic/ (1847)

  - /An Investigation of the Laws of Thought/ (1854)

[[file:images/George_Boole_color.jpg]][fn:1]

* Logischer Schluss
:PROPERTIES:
:CUSTOM_ID: logischer-schluss
:END:

Logische Folgerungen (Beweise)

- logischer Schluss

  - aus einer Reihe von Annahmen \(A_1,\ldots,A_n\) (Voraussetzungen,
    Prämissen) soll eine Schlussfolgerung \(B\) (Konklusion) gezogen
    werden

  - formelmäßig ausgedrückt:
    \(A_1 \land \ldots \land A_n \rightarrow B\)

  - Bezeichnung: \(\left\{A_1, A_2, \ldots, A_n\right\} \models B\) bzw.
    \(A_1, A_2, \ldots, A_n \models B\)

- Beweisfolge

  - Aus einer Menge von Prämissen oder bereits abgeleiteten Aussagen
    werden durch Anwendung von Ableitungsregeln neue Aussagen
    abgeleitet, die im Weiteren ebenfalls benutzt werden können;
    entspricht Kettenschluss
    \(((A_1 \rightarrow A_2) \land (A_2 \rightarrow A_3)) \rightarrow (A_1 \rightarrow A_3)\)

  - Ableitungsregeln sind entweder Äquivalenzregeln (äquivalente
    Ersetzungen gemäß Boolescher Rechenregeln) oder Schlussregeln
    (geeignete Tautologien)

Schlussregeln

- \((A \land (A \rightarrow B)) \rightarrow B\) (Modus ponens)\\
  "wenn A gilt und aus A folgt B, dann gilt B"

- \(((A \rightarrow B) \land \neg B) \rightarrow \neg A\) (Modus
  tollens)\\
  "wenn aus A B folgt und B nicht gilt, dann gilt A nicht"

- \(A \land B \rightarrow (A \land B)\) (Konjunktion)\\
  "wenn A und B bereits gezeigt sind, dann gilt auch die Verknüpfung
  \(A \land B\)"

- \(A \land B \rightarrow A\) (Vereinfachung)\\
  "wenn A und B gelten, dann gilt insbesondere auch A"

- \(A \rightarrow (A \lor B)\) (Ausdehnung)\\
  "ist A bereits gezeigt, dann gilt auch A oder B"

Bemerkungen und Beispiel

- Zweckmäßige Tipps

  - Formeln \(\neg (A \land B)\) bzw. \(\neg (A \lor B)\) umschreiben
    als \((\neg A \lor \neg B)\) bzw. \((\neg A \land \neg B)\)

  - \(A \lor B\) überführen in Implikation \(\neg A \rightarrow B\)

  - Ist als Konklusion B eine Implikation zu zeigen, d.h.\\
    \((A_1 \land \ldots \land A_k) \rightarrow (C \rightarrow D)\), dann
    kann stattdessen auch\\
    \((A_1 \land \ldots \land A_k) \rightarrow D\) gezeigt werden

- Beispiel\\
  es gelten die Prämissen:
  \(A, B \rightarrow C, (A \land B) \rightarrow (D \lor \neg C), B\);\\
  zeige: \(D\)

Beweistypen (deduktiv)

1. _direkter Beweis_ \(A \rightarrow B\)

2. Beweis durch _Umkehrschluss_ (Kontraposition): zeige
   \(\neg B \rightarrow \neg A\)

3. _Widerspruchsbeweis:_ zeige \((A \land \neg B) \rightarrow f\)

4. _Äqzivalenzbeweis:_\\
   zu zeigen: \(A \leftrightarrow B\)\\
   stattdessen:\\
   \(A \rightarrow B\) und \(B \rightarrow A\) bzw. \(A \rightarrow B\)
   und \(\neg A \rightarrow \neg B\)

5. Beweis durch _Fallunterscheidung:_\\
   zeige A durch \(B \rightarrow A\) und \(\neg B \rightarrow A\)

6. Beweis _atomararer Aussagen:_\\
   zeige A durch \(w \rightarrow A\) bzw. \(\neg A \rightarrow f\)

Erläuterungen

1. da \(A \rightarrow B\) nur falsch sein kann für \(I(A)=w\) und
   \(I(B)=f\), genügt es, \(A\) als wahr anzunehmen und \(I(B)=w\) zu
   zeigen (\(B\) abzuleiten)

2. \((\neg B \rightarrow \neg A) \equiv A \rightarrow B\)

3. \((A \land \neg B) \rightarrow f \equiv A \rightarrow B\)

4. \(A \leftrightarrow B \equiv (A \rightarrow B) \land (B \rightarrow A)\)

5. \(A \equiv (B \rightarrow A) \land (\neg B \rightarrow A)\)

6. \(A \equiv w \rightarrow A \equiv \neg A \rightarrow f\)

Exkurs: Methode der vollständigen Induktion

- sei \(A(n), n=0,1,\ldots\) eine Folge von Aussagen, die zu beweisen
  sind

- Induktionsbeweis

  - Induktionsbasis: zeige \(A(0)\)

  - zeige für alle \(n: A(n) \rightarrow A(n+1)\)

  - alternative Formulierung

    - Induktionsvoraussetzung: \(A(n)\) für ein beliebig gewähltes n

    - Induktionsschluss: zeige \(A(n+1)\) aus \(A(n)\)

- Verallgemeinerte vollständige Induktion

  - Zeige \(A(0)\)

  - Zeige
    \(A(0) \land A(1) \land \ldots \land A(n) \rightarrow A(n+1)\)\\
    zum Beweis von \(A(n)\) kann auf die Gültigkeit von \(A(m)\) für
    beliebige \(m<n\) zurückgegriffen werden

Beispiele Beweistechniken seien \(a, b\) natürliche Zahlen

- direkter Beweis: wenn \(a\) teilbar ist durch 6, dann ist \(a\) auch
  teilbar durch 3

- Beweis durch Kontraposition: wenn \(a^2\) ungerade, dann auch \(a\)

- Widerspruchsbeweis: wenn \(a\) und \(b\) gerade, dann auch
  \(a \cdot b\)

- Äquivalenzbeweis: \(a\) ist gerade genau dann wenn \(a^2\) gerade ist

- Beweis durch Fallunterscheidung: \(a^2\) geteilt durch \(4\) liefert
  Rest \(1\) oder \(0\)

- Beweis atomarer Aussagen: \(\sqrt{2}\) ist keine rationale Zahl

- Induktionsbeweis:

  - zeige: \(s_n := \sum_{i=1}^{n}i=\frac{n(n+1)}{2}\) (dazu auch
    direkten Beweis)

  - Fibonacci-Folge: \(f_1=1, f_2=1, f_n=f_{n-1}+f_{n-2} (n>2)\)\\
    zeige: \(f_n=\frac{1}{\sqrt{5}}(A^n-B^n)\) mit
    \(A=\frac{1+\sqrt{5}}{2}\) und \(B=\frac{1-\sqrt{5}}{2}\)

* Erfüllbarkeit aussagenlogischer Formeln
:PROPERTIES:
:CUSTOM_ID: erfüllbarkeit-aussagenlogischer-formeln
:END:

Entscheidungsproblem SAT

- Ist eine gegebene aussagenlogische Formel erfüllbar / nicht erfüllbar?

- Gesucht sind /Algorithmen/ (Verfahren, Handlungsanweisungen), die für
  eine (beliebige) aussagenlogische Formel als Eingabe nach endlich
  vielen Schritten mit (korrekter) Aussage ja/nein terminieren.

- trivialer Algorithmus: Berechnung der Wahrheitstafel \(\rightarrow\)
  nicht effizient

- Bemerkung: jede aussagenlogische Formel lässt sich effizient in eine
  erfüllbarkeitsäquivalente Formel in KNF umschreiben (unter Einführung
  zusätzlicher Variablen) \(\rightarrow\) betrachte im weiteren Formeln
  in KNF

Klauselmengen

- Mengennotation für Formeln in KNF\\
  ersetze Klausel \(L_{i1} \lor L_{i2} \lor \ldots\) durch
  \(C_i = \left\{L_{i1}, L_{i2}, \ldots\right\}\) und Formel \(F\) in
  KNF durch Klauselmenge \(S=\left\{C_1, C_2, \ldots\right\}\)

- Belegung \(I\) lässt sich ebenfalls als Menge darstellen:\\
  z.B. \(I(x_1)=w, I(x_2)=f, \ldots\)\\
  dann Schreibweise \(I=\left\{x_1, \overline{x_2}, \ldots\right\}\)

- Belegung \(I\) ist Modell der Klausel \(C_i\) gdw.
  \(I \cap C_i \neq \varnothing\).\\
  Belegung \(I\) ist Modell der Klauselmenge \(S\) gdw.
  \(I \cap C_i \neq \varnothing\) für alle \(C_i \in S\).

Hornformeln

- Definition: \(F\) ist Hornformel gdw. \(F\) ist in KNF und jede
  Klausel enthält höchstens ein positives Literal.

- Beispiel:
  \(F_1=(A \lor \neg B) \land (\neg C \lor \neg A \lor D) \land (\neg A \lor \neg B) \land D \land \neg E\)

- Es gilt: jede Hornformel lässt sich äquivalent in eine Konjunktion von
  Implikationen ("Regeln") umformen

- Beispiel:
  \(F_1=(B \rightarrow A) \land (A \land C \rightarrow D) \land (A \land B \rightarrow f) \land (w \rightarrow D) \land (E \rightarrow f)\)

- Eine Menge von Hornklauseln heißt auch Logikprogramm

  - Tatsachenklausel: ein positives und kein negatives Literal

  - Prozedurklausel (Regel): ein positives und mindestens ein negatives
    Literal

  - Zielklausel (Frageklausel): negative Klausel (ohne positives
    Literal)

Beweismethodik

- Zeige Gültigkeit einer regelbasierten aussagenlogischen Formel durch
  Nichterfüllbarkeit von \(\neg F\)

- Beispiel: es gelten die Prämissen \(B, B \rightarrow A\) und
  \((A \land B) \rightarrow C\); logisches Schließen liefert \(A\) und
  daraus auch \(C\); also ist\\
  \(F=(B \land (B \rightarrow A) \land (A \land B \rightarrow C)) \rightarrow (A \land C)\)\\
  eine Tautologie. Es gilt\\
  \(\neg F = B \land (B \rightarrow A) \land (A \land B \rightarrow C) \land (\neg A \lor \neg C)\)\\
  das ist Hornformel, mit Zielklausel
  \((\neg A \lor \neg C) \equiv ((A \land C) \rightarrow f)\)

- Anstelle die Gültigkeit von F direkt zu beweisen, zeige die
  Nichterfüllbarkeit der Hornformel \(\neg F\)

Erfüllbarkeitstest (Markierungsalgorithmus) Sei F Konjunktion von
Implikationen

1. Für alle Teilformeln der Art \(w \rightarrow A\): markiere in allen
   Teilformeln auftretende \(A\)

2. while (es gibt Teilformeln der Art

   1. \(A_1 \land A_2 \land \ldots \land A_n \rightarrow B\) bzw.
      \(1 \rightarrow B\) oder

   2. \(A_1 \land A_2 \land \ldots \land A_n \rightarrow f\)\\
      mit: alle \(A_i\) markiert, \(B\) nicht markiert)\\
      if (Fall (i)) markiere alle B\\
      else (Fall (ii)) Rückgabe "`unerfüllbar, STOP\\
      end

   end\\
   Rückgabe "erfüllbar"\\
   STOP

Beispiel: Markierungsalgorithmus
\[F=(\neg A \lor \neg B \lor \neg D) \land \neg E \land (\neg C \lor A) \land C \land B \land (\neg G \lor D) \land G\]

Erfüllbarkeitstest (Hornklauselalgorithmus) Sei \(S\) Menge von
Hornklauseln\\
while (\(S\) enthält eine positive Klausel \(\left\{A_i\right\}\))\\
entferne alle Klauseln, die \(A_i\) enhalten\\
und entferne \(\overline{A_i}\) aus den verbliebenen Klauseln\\
end\\
if (\(S\) enhält die leere Klausel \(\Box\))\\
Rückgabe "unerfüllbar"\\
else Rückgabe "erfüllbar"\\
end

Erfüllbarkeit allgemeiner Klauselmengen: Davis-Putnam-Regeln

- Sei \(S=\left\{K_1, \ldots, K_k\right\}\) Klauselmenge, \(L\) ein
  Literal, \(\overline{L}\) das negierte Literal. Definiere:

  - \(S_L^+=\left\{K_j \in S \mid L \in K_j\right\}, S_L^-=\left\{K_j \in S \mid \overline{L} \in K_j\right\}, S_L^0=\left\{K_j \in S \mid L, \overline{L} \notin K_j\right\}\)

  - \(POS_L(S)=S_L^0 \bigcup \left\{K_j \setminus \left\{L\right\} \mid K_j \in S_L^+\right\}; NEG_L(S)=S_L^0 \bigcup \left\{K_j \setminus \left\{\overline{L}\right\} \mid K_j \in S_L^-\right\}\)

- Es gilt: Die Klauselmenge \(S\) ist erfüllbar gdw. wenigstens eine der
  beiden Klauselmengen \(POS_L(S)\) und \(NEG_L(S)\) erfüllbar ist

  - Vorteil: Anzahl der Literale wird schrittweise reduziert

  - Nachteil: in jedem Schritt verdoppelt sich i.A. die Zahl der
    Klauselmengen (vielfach aber auch nicht, s.u.)

- Spezialfälle

  - \(S_L^-=\varnothing\): S erfüllbar gdw. \(NEG_L(S)=S_L^0\) erfüllbar
    (analog für \(S_L^+=\varnothing\))

  - Unit-Regel: falls \(\left\{L\right\} \in S\), dann \(S\) erfüllbar
    gdw. \(NEG_L(S)\) erfüllbar

Resolution

- Beweis der Unerfüllbarkeit allgemeiner Klauselmengen durch Herleitung
  der leeren Klausel

- Definition: Resolvente

  - sei \(L\) ein Literal und \(\overline{L}\) das negierte Literal

  - sei \(K_1\) eine Klausel, die \(L\) enthält, \(K_2\) eine Klausel,
    die \(\overline{L}\) enthält

  - dann heißt die Klausel
    \(RES_L(K_1, K_2)=\left(K_1 \setminus \left\{L\right\}\right) \cup \left(K_2 \setminus \left\{\overline{L}\right\}\right)\)

  - Gesprochen: "Resolvente der Klauseln \(K_1\) und \(K_2\) nach \(L\)"

  - Notation: \(\left\{K_1, K_2\right\} \vdash_{res} RES_L\)

- Resolutionslemma\\
  sei \(I\) ein Modell von \(K_1\) und \(K_2\), dann ist \(I\) auch
  Modell von \(RES_L(K_1, K_2)\), d.h.
  \(I \cap K_1 \neq \varnothing \land I \cap K_2 \neq \varnothing \rightarrow I \cap RES_L(K_1, K_2) \neq \varnothing\)

Grundresolutionstheorem

- Zu \(S\) erfüllbarkeitsäquivalente Klauselmenge \(RES_L(S)\)

  - sei \(S\) Klauselmenge; \(n\) Anzahl der Variablen; definiere:\\
    \(RES_L(S)=S_L^0 \bigcup \left\{RES_L(K_1, K_2) \mid K_1 \in S_L^+, K_2 \in S_L^-\right\}\)

  - beachte: \(RES_L(S)\) enhält \(L\) bzw. \(\overline{L}\) nicht mehr

  - es gilt: \(S\) ist erfüllbar gdw. \(RES_L(S)\) ist erfüllbar

- Grundresolutionstheorem: eine Klauselmenge \(S\) ist unerfüllbar gdw.
  \(S\) lässt sich mittels Resolution widerlegen, d.h. die leere Klausel
  ist herleitbar

- Systematische Durchführung:\\
  \(S_0=S\), \(S_i=RES_{L_i}\left(S_{i-1}\right)\); alle
  \(S_i, i \leq n\) sind erfüllbarkeitsäquivalent\\
  \(S_n\) enthält kein Literal mehr, d.h. \(S_n=\varnothing\)
  (erfüllbar) oder \(S_n=\left\{\Box\right\}\) (unerfüllbar)

Resolution: Beispiel und Hinweis

- Ist folgende Formel (un-)erfüllbar?:
  \((\neg A \lor B) \land (\neg B \lor C) \land A \land \neg C\)

- *Vorsicht!*

  - \(\left\{A, \neg B\right\}\) und \(\left\{\neg A, B\right\}\) haben
    als Resolvente *nicht* \(\Box\)! Es wird immer nur ein
    (komplementäres) Literal entfernt!

  - \(\left\{B, \neg B\right\}\) führt nicht zu \(\Box\)! Es werden
    immer zwei Klauseln benötigt!

* Einführung: Sprachen und Grammatiken
:PROPERTIES:
:CUSTOM_ID: einführung-sprachen-und-grammatiken
:END:

Sprachen: Bezeichnungen, Regeln

- Alphabet \(\Sigma\): Menge von Symbolen (Buchstaben)

- \(\Sigma^*\):

  - Menge aller Worte, die sich durch Hintereinanderschreiben
    ("Konkatenation") von Buchstaben aus \(\Sigma\) bilden lassen

  - Beispiel:
    \(\Sigma=\left\{a,b\right\}, \Sigma^*=\left\{\varepsilon, a, b, aa, \ldots\right\}, \varepsilon\):
    "leeres Wort", \(\varepsilon a=a \varepsilon = a\)

  - Länge eines Wortes
    \(|w|: |a|=1, |\varepsilon|=0, |w_1w_2|=|w_1|+|w_2|\)

- Sprache \(L\): Teilmenge von \(\Sigma^*\)

  - Es gelten die Mengen-Verknüpfungen
    \(L_1 \cup L_2, L_1 \cap L_2, L_1 \setminus L_2\)

  - Dazu die Konkatenation
    \(L_1L_2=\left\{xy \mid x \in L_1 \land y \in L_2\right\}\)

  - Regeln:\\
    \(L^0=\left\{\varepsilon\right\}, L^1=L, L^{n+1}=LL^n, L^*=\bigcup_{n\geq0}L^n, L^+=\bigcup_{n\geq1}L^n\)

Grammatiken

- generierende Grammatik \(G\): Sprache durch Regeln erzeugen

- Definition: \(G=(V, \Sigma, P, S)\) mit\\
  \(V\): endliche Menge von Variablen\\
  \(\Sigma\): Terminalalphabet, \(V \cap \Sigma = \varnothing\)\\
  \(P\): Menge von Regeln (Produktionen) der Art
  \(u_1 \rightarrow u_2\), mit
  \(u_1, u_2 \in \left(V \cup \Sigma\right)^*\)\\
  \(S\): Startvariable, \(S \in V\)

- Ableitung \(S \underset{G}{\Rightarrow}^* w\)

  - Ableitungsschritt
    \(u \underset{G}{\Rightarrow} v: u=xyz, v=xy'z, y\rightarrow y' \in P\)

  - \(\underset{G}{\Rightarrow}^*\): reflexive und transitive Hülle der
    Relation \(\underset{G}{\Rightarrow}\) (endliche Folge)

- durch \(G\) erzeugte Sprache:
  \(L(G)=\left\{w \in \Sigma^* \mid S \underset{G}{\Rightarrow}^* w\right\}\)

Chomsky-Hierarchie

- Hierarchie von Grammatiken

  - Startwort besteht aus genau einer Variablen \(S\),\\
    es gibt keine Regeln der Art \(\varepsilon \rightarrow u\) (Wörter
    dürfen nicht aus dem "Nichts" entstehen)

  - (kontextsensitiv) Typ 0, und für alle Regeln \(w_1 \rightarrow w_2\)
    gilt: \(|w_1| \leq |w_2|\);\\
    \(S \rightarrow \varepsilon\) als Sonderregel erlaubt

  - (kontextfrei) Typ 1, und für alle Regeln \(w_1 \rightarrow w_2\)
    gilt: \(w_1\) ist eine einzelne Variable

  - (regulär) Typ 2, und für alle Regeln \(w_1 \rightarrow w_2\) gilt:
    \(w_2 \in \Sigma \cup \Sigma V\)

- _\(\varepsilon\)-Sonderregel_: \(\varepsilon\) darf nur aus
  Startsymbol \(S\) abgeleitet werden;\\
  \(S\) darf dann auf keiner rechten Seite einer Regel vorkommen

Beispiel Typ-1 Grammatik \[\begin{aligned}
		L&=\left\{a^nb^nc^n \mid n \geq 1\right\}\\
		G&=\left(\left\{S,B,C\right\},\left\{a,b,c\right\},P,S\right)\\
		P&=\{S \rightarrow aSBC \mid aBC,\\
		         &\qquad CB \rightarrow BC,\\
		         &\qquad aB \rightarrow ab,\\
		         &\qquad bB \rightarrow bb,\\
		         &\qquad bC \rightarrow bc,\\
		         &\qquad cC \rightarrow cc\}\\
	
\end{aligned}\]

Ableitungsbaum

- Darstellung der Ableitungsschritte als Baum

- Links- bzw. Rechtsableitungen

- Mehrdeutige Grammatiken

  - zu ein und demselben Terminalwort existieren verschiedene (Links-)
    Ableitungen

  - Eine Sprache \(L\) heißt /inhärent mehrdeutig/, falls keine
    eindeutige Grammatik für \(L\) existiert

- Berechnung von Ausdrücken:

  - Operanden, die im Ableitungsbaum tiefer liegen, haben bei der
    Ausführung höhere Priorität

  - Compiler erzeugt Ableitungsbaum bottom-up durch Ableitung des
    Startsymbols aus dem Terminalwort

  - benutzt dazu /reduktive/ Grammatik: erzeugt aus der /generativen/
    Grammatik durch Transponieren der Regeln

Avram Noam Chomsky ()

- US-amerikanischer Linguist, Philosoph, Kognitionswissenschaftler

- Begründer der generativen Grammatik, Chomsky-Hierarchie

- emeritierter Professor für Linguistik am MIT

- politisch sehr aktiv

- Schriften:

  - /Syntactic Structure/ (1957)

  - /The Logical Structure of Linguistic Theory/\\
    (veröffentlicht 1975)

[[file:images/Noam_Chomsky_portrait_2017_retouched.jpg]][fn:2]

* Reguläre Sprachen und Endliche Automaten
:PROPERTIES:
:CUSTOM_ID: reguläre-sprachen-und-endliche-automaten
:END:

Endliche Automaten (Finite-State Machine (FSM), Finite Automaton (FA))

- Grundkonzept

  - FSM befinden sich jeweils in genau /einem/ aus einer /endlichen
    Menge/ von Zuständen

  - FSM reagieren auf Eingaben, führen dabei gegebenenfalls Aktionen aus
    und wechseln ihren Zustand (Übergang, Transition)

- Einsatz zur Spracherkennung

  - Folge von Eingaben kann aufgefasst werden als Wort über einem
    Alphabet (Eingabe jeweils ein Buchstabe)

  - Eingabenfolge entspricht einem Wort der vom FSM \(A\) akzeptierten
    Sprache \(L(A)\) gdw.

    - das Wort vollständig gelesen wird und

    - sich \(A\) danach in einem der vorab definierten Endzustände
      befindet

  - Wort wird nicht generiert (Grammatik) sondern akzeptiert (als
    zugehörig erkannt)

Exkurs: Tools zur Simulation von Automaten

- [[https://www.jflap.org/]]

- [[https://flaci.com]]

Deterministischer Endlicher Automat (DFA)

- Allgemeine Spezifikation eines DFA \(A\):\\
  \(A=\left(S, \Sigma, \delta, s_0, F\right)\)

  - \(S\): endliche Menge von Zuständen

  - \(\Sigma\): Alphabet

  - \(\delta:S \times \Sigma \rightarrow S\) Überführungsfunktion

  - \(s_0\): Startzustand, \(s_0 \in S\)

  - \(F\): Menge (akzeptierender) Endzustände, \(F \subseteq S\)

- Graphische Darstellung: Zustände als Knoten eines Graphen
  (Zustandsgraph)\\

Beispiel DFA \[\begin{aligned}
		A &= (S, \Sigma, \delta, s_0, F)\\
		S &= \left\{s_0, s_1, s_2, s_3\right\}\\
		\Sigma &= \{a, b\}\\
		F &= \{s_3\}\\
		\delta &= \{(s_0, a, s_1), (s_0, b, s_3), (s_1, a, s_2), (s_1, b, s_0), \\
		& \qquad (s_2, a, s_3), (s_2, b, s_1), (s_3, a, s_0), (s_3, b, s_2)\}
	
\end{aligned}\]

Durch DFA akzeptierte Sprachen: Reguläre Sprachen

- Konfiguration des Automaten: \(A: (s,u)\)

  - \(s\): aktueller Zustand

  - \(u\): noch zu lesendes Teilwort

- Konfigurationsübergang\\
  \((s, av) \mapsto (s', v) \leftrightarrow \delta(s,a) = s'\)

- Durch \(A\) akzeptierte Sprache\\
  \(L(A) = \left\{w \in \Sigma^* \mid (s_0,w) \mapsto^* (s_f, \varepsilon), s_f \in F \right\}\)

- es gilt: reguläre Sprachen sind Teilmenge der Typ-3-Sprachen\\

  - konstruiere zu \(A\) eine korrespondierende Grammatik
    \(G=(S,\Sigma,P,S_0)\)\\

  - \(S_i=s_i\), insbesondere \(S_0=s_0\)

  - für jeden Übergang \(\delta(s,a)=s'\) die Regel
    \(S \rightarrow aS'\)\\
    zusätzlich die Regeln \(S \rightarrow a\), falls \(s'\) Endzustand
    und \(S_0 \rightarrow \varepsilon\), falls \(s_0\) Endzustand

Nichtdeterministische endliche Automaten (NFA)

- Ausgangspunkt: Typ-3-Grammatiken erlauben Regeln der Art\\
  \(S_1 \rightarrow aS_2 \mid aS_3\)

- korrespondierende nichtdeterministische Automaten: zu einem Zustand
  \(s_1\) kann es bei Eingabe \(a\) Übergänge zu verschiedenen Zuständen
  \(s_2, s_3\) geben

- \(\delta\) ist dann keine Abbildung, sondern eine allgemeinere
  Transitionsrelation:\\
  \(\delta \subseteq (S \times \Sigma) \times S\)

- akzeptierte Sprache:\\
  \(L(A)=\left\{w \in \Sigma^* \mid (s_0,w) \mapsto^* (s_f, \varepsilon), s_f \in F, s_0 \in S_0 \right\}\)

  - \(w\) wird akzeptiert, falls es eine akzeptierende Folge von
    Konfigurationsübergängen gibt; andere Folgen müssen nicht
    akzeptierend sein

  - \(S_0:\) Menge von Startzuständen (mehrere sind erlaubt)

Beispiel NFA

\\
\(A=(S, \Sigma, \delta, S_0, F)\)\\
\(S=\{s_0, s_1, s_2\}\)\\
\(S_0=\{s_0, s_1\}\)\\
\(\Sigma=\{0,1\}\)\\
\(F=\{s_2\}\)\\
\(\delta=\{(s_0,0,s_0), (s_0, 1, s_0), (s_0, 0, s_1), (s_1, 0, s_2)\}\)\\
Akzeptierte Sprache:
\(L(A)=\left\{w \in \Sigma^* \mid w=0 \lor w=x00, x\in \Sigma^*\right\}\)

Simulation des Verhaltens von NFAs

- Backtracking: Tiefensuche

  - Jeweils eine mögliche Alternative wird weiter verfolgt
    \(\rightarrow\) Tiefensuchbaum

  - bei "Sackgasse": zurück (aufwärts im Baum) bis zur nächsten freien
    Alternative

  - Abbruch, wenn akzeptierende Konfigurationsfolge gefunden oder sonst
    alle möglichen Konfigurationsfolgen untersucht

- Breitensuche:

  - parallele schrittweise Verfolgung aller Verzweigungen
    (Breitensuchbaum)

  - Darstellung von \(\delta\) als mengenwertige Funktion
    \(\delta: S \times \Sigma \rightarrow \mathcal{P}(S)\)

  - Erweiterung auf Folge von Konfigurationsübergängen\\
    \(\hat{\delta}: \mathcal{P}(S) \times \Sigma^* \mapsto \mathcal{P}(S)\)\\
    \(\hat{\delta}(S', \varepsilon) = S'\)
    \(\hat{\delta}(S', av)=\hat{\delta}\left(\bigcup_{s \in S}, \delta(s,a),v\right)\)
    \((S' \in \mathcal{P}(S))\)

  - Akzeptierte Sprache\\
    \(L(A)=\left\{w \in \Sigma^* \mid \hat{\delta}(S_0,w)\cap F \neq \varnothing\right\}\)

Äquivalenz von DFA und NFA

- jede durch einen NFA akzeptierte Sprache kann auch durch einen DFA
  akzeptiert werden (umgekehrt sowieso)

- Konstruktiver Beweis: Potenzmengenkonstruktion für _DFA_ \(A_d\)
  äquivalent zu NFA \((S, \Sigma, \delta, S_0, F)\)\\
  \(A_d=\left(S_d, \Sigma, \delta_d, s_0^d, F_d\right)\) mit\\
  \(S_d=\mathcal{P}(S)\); \(s_0^d=S_0 \in \mathcal{P}(S)\);
  \(\delta_d(S', a)=\bigcup_{s \in S}\)
  \(\delta(s, a) \in \mathcal{P}(S)\)\\
  \(F_d = \left\{S' \in \mathcal{P}(S) \mid S' \cap F \neq \varnothing\right\} \subseteq \mathcal{P}(S)\)

- es gilt: \(w \in L(A)\) gdw.
  \(\hat{\delta}(S_0, w) \cap F \neq \varnothing\)\\
  gdw. \((s_0^d, w) \mapsto^* (s_f^d, \varepsilon), s_f^d \in F_d\) gdw.
  \(w \in L(A_d)\)

- Nutzen: mit NFA kann eine Sprache leichter modelliert werden
  \(\rightarrow\) zur Anwendung in DFA umrechnen

Algorithmus zur Umwandlung NFA in DFA (verbal) NFA:
\(A_n=(S_n, \Sigma, \delta_n, S_0^n, F_n)\), DFA:
\(A_d=(S_d, \Sigma, \delta_d, s_0^d, F_d)\)

1. \(S_d\) ist die Potenzmenge von \(S_n\)

2. \(s_0^d\) ist das Element aus \(S_d\), das die Kombination aller
   Startzustände aus \(S_0^n\) repräsentiert. Aus (möglicherweise)
   vielen Startzuständen in \(S_n\) wird somit genau ein Startzustand
   \(s_0^d\).

3. Jede Kombination in \(S_d\), die mindestens einen Endzustand aus
   \(F_n\) enthält, wird zum Endzustand in \(F_d\).

4. Für jede Zustandskombination in \(S_d\) wird ermittelt, welche
   Zustände mit dem Eingabesymbol \(a \in \Sigma\) erreichbar sind.
   Diese Kombination wird zur Übergangsfunktion \(\delta_d\)
   hinzugefügt.

Beispiel: Umwandlung NFA in DFA (Berechnung) Beispiel zur Umwandlung des
NFA aus Folie [[#NFA_Beispiel][[NFA_Beispiel]]] in DFA:

- \(S_d=\{\varnothing, s_0, s_1, s_2, s_0s_1, s_0s_2, s_1s_2, s_0s_1s_2\}\)

- \(s_0^d=s_0s_1\)

- \(\Sigma=\{0,1\}\) (unverändert)

- \(F_d=\{s_2, s_0s_2, s_1s_2, s_0s_1s_2\}\)

- \(\delta_d=\{(\varnothing, 0, \varnothing), (\varnothing, 1, \varnothing), (s_0, 0, s_0s_1), (s_0, 1, s_0), (s_1, 0, s_2), (s_1, 1, \varnothing),\)\\
  \((s_2, 0, \varnothing), (s_2, 1, \varnothing), (s_0s_1, 0, s_0s_1s_2),(s_0s_1, 1, s_0),\)\\
  \((s_0s_2, 0, s_0s_1), (s_0s_2, 1, s_0), (s_1s_2, 0, s_2), (s_1s_2, 1, \varnothing),\)\\
  \((s_0s_1s_2, 0, s_0s_1s_2), (s_0s_1s_2, 1, s_0)\}\)

- Für den DFA \(A_d\) sind die Zustände
  \(\varnothing, s_1, s_2, s_1s_2\) und \(s_0s_2\) nicht relevant, da
  sie vom Startzustand \(s_0s_1\) aus nicht erreicht werden können.

Beispiel: Umwandlung NFA in DFA (Zustandsgraph)

Nur relevante Zustände:

Äquivalenz von Typ-3-Sprachen und regulären Sprachen

- Menge der regulären Sprachen Teilmenge der Typ-3-Sprachen:\\
  \(\rightarrow\) schon gezeigt (DFA)

- Menge der Typ-3-Sprachen Teilmenge der regulären Sprachen:\\
  Beweis: konstruiere zu gegebener Typ-3-Grammatik einen (i.A.
  nichtdeterministischen) FA\\

  ̄ \(G=(V,\Sigma, P, S_0)\) \(FA=(S, \Sigma, \delta, s_0, F)\)\\
  intialisiere:
  \(S=V \cup \left\{f\right\}, s_0=S_0, \delta=\varnothing\)\\
  \(F=\left\{f\right\}\) (neues Symbol \(f\))\\
  Regel \(A \rightarrow aB\) füge ein: \((A, a, B) \in \delta\)\\
  Regel \(A \rightarrow a\) füge ein: \((A, a, f) \in \delta\)\\
  Regel \(S_0 \rightarrow \varepsilon \mid S_1\) füge \(S_0\) in \(F\)
  ein; für \(S_1\) die Regeln für \(S_0\)\\
  einsetzen (Kettenregel); \(S_1\) verbleibt als Zustand

Minimalautomat

- Ausgangspunkt: ein DFA;\\
  Ziel: konstruiere einen äquivalenten DFA mit geringster Anzahl von
  Zuständen

- Konstruktion

  1. Beginne mit einer Partition \(P_1=\left\{S_{11}, S_{12}\right\}\)
     der Zustandsmenge \(S\) in \(S_{11}=F, S_{12}=S \setminus F\)

  2. bilde aus \(P_i=\left\{S_{i1},\ldots,S_{ik}\right\}\) die Partition
     \(P_{i+1}\) durch folgende Verfeinerung:\\
     teile \(S_{ij}\), falls es in \(S_{ij}\) Zustände \(s\) und \(s'\)
     gibt mit:\\
     für ein \(a \in \Sigma\) liegen \(\delta(s, a)\) und
     \(\delta(s', a)\) in unterschiedlichen Blöcken \(S_{il}\) von
     \(P_i\)

  3. Minimalautomat erreicht, wenn \(P_{i+1}=P_i\);\\
     die \(S_{ij}\) bilden dann die Zustände des Minimalautomaten

- Minimalautomat kann alternativ auch durch schrittweises Zusammenfassen
  von Zuständen konstruiert werden (insbesondere falls Menge der
  Nichtendzustände leer)

Beispiel: Minimalautomat (Ausgangssituation)

Beispiel: Minimalautomat (Ergebnis)

| \(s_0\) | -       | -       | -       | -       | -       |
|---------+---------+---------+---------+---------+---------|
| \(s_1\) | X       | -       | -       | -       | -       |
| \(s_2\) |         | X       | -       | -       | -       |
| \(s_3\) | X       |         | X       | -       | -       |
| \(s_4\) | X       | X       | X       | X       | -       |
|         | \(s_0\) | \(s_1\) | \(s_2\) | \(s_3\) | \(s_4\) |

Abgeschlossenheit regulärer Sprachen Seien \(L, L_1, L_2\) reguläre
Sprachen. Dann sind auch die folgenden Sprachen regulär:

- jede endliche Sprache \(L_{3} \subset \Sigma^*\)

- \(L = \Sigma^*\)

- \(L_1 \cup L_2\)

- \(L_1 \setminus L_2\) (und damit auch Komplement
  \(\Sigma^* \setminus L\))

- \(L_1 \cap L_2\)

- \(L_1L_2\)

- \(L^*\)

- \(\tilde{L}\) (gespiegelte Sprache)

/Kleene's Theorem/\\
Eine Sprache \(L\) ist regulär gdw. sie lässt sich durch endlich viele
Anwendungen der Operationen Vereinigung, Konkatenation und \(*\) aus
einer endlichen Sprache erzeugen.

Reguläre Ausdrücke

- Zweck: Mittel zur Beschreibung regulärer Sprachen

- Induktive Definition regulärer Ausdrücke \(\alpha\) über \(\Sigma\)

  - \(\varnothing\) ist ein regulärer Ausdruck:
    \(L(\varnothing)=\varnothing\)

  - \(\varepsilon\) ist ein regulärer Ausdruck:
    \(L(\varepsilon)=\left\{\varepsilon\right\}\)

  - für jedes \(a \in \Sigma\) ist \(a\) ein regulärer Ausdruck:
    \(L(a)=\left\{a\right\}\)

  - sind \(\alpha\) und \(\beta\) reguläre Ausdrücke, dann auch
    \(\alpha^*\), \(\alpha\beta\) und \(\alpha | \beta\)\\
    \(L(\alpha^*)=(L(\alpha))^*,\)
    \(L(\alpha|\beta)=L(\alpha)\cup L(\beta),\)
    \(L(\alpha\beta)=L(\alpha)L(\beta)\)

  - nur die so gebildeten Ausdrücke sind regulär

- "Rechenregeln" bzw. Bezeichnungen\\
  \(\varnothing|\alpha=\alpha;\) \(\varnothing\alpha=\varnothing;\)
  \(\varnothing^*=\varepsilon;\) \(\varepsilon\alpha=\alpha;\)
  \(\alpha|\alpha=\alpha;\) \(\alpha^+:=\alpha\alpha^*;\)
  \(\alpha^+|\varepsilon=\alpha^*\)

- Kleene's Theorem (umformuliert)\\
  Eine Sprache \(L'\) ist regulär gdw.\\
  es existiert ein regulärer Ausdruck \(\alpha\) mit \(L'=L(\alpha)\).

- Siehe auch: https://stackoverflow.com/questions/1732348

\(\varepsilon\)-Automaten (\(\varepsilon\)FA)

- Definition: Erweiterung von NFA; es werden Zustandsübergänge
  zugelassen ohne Lesen eines Zeichens\\
  \(\delta\subseteq S \times \left(\Sigma \cup \left\{\varepsilon\right\}\right) \times S\)

- Nutzen:

  - besonders geeignet zum Zusammensetzen von Automaten aus
    Teilautomaten

  - Umsetzung regulärer Ausdrücke in \(\varepsilon\)-Automaten, danach
    in NFA und damit auch in DFA umrechenbar

- Beispiel: \(\alpha=a^*b^*\)

Zusammengesetzte Automaten

0.5

0.5 Top-Down-Zugang: zerlege den durch den regulären Ausdruck \(\alpha\)
beschriebenen Automaten in Teilbestandteile

Äquivalenz von \(\varepsilon\)FA und NFA Konstruktion eines zu einem
\(\varepsilon\)FA äquivalenten NFA

1. erweitere \(A\) um zwei Zustände \(i\) und \(f\);
   \(\varepsilon\)-Übergänge von \(i\) zu allen Anfangszuständen aus
   \(S_0\), sowie von allen Endzuständen aus \(F\) zu \(f\)

2. eliminiere alle \(\varepsilon\)-Zyklen; die betroffenen Zustände
   werden zu einem neuen Zustand zusammengefasst; verbleibende
   \(\varepsilon\)-Übergänge des neuen Zustands auf sich selbst werden
   entfernt

3. Neue Übergänge einfügen: gibt es einen \(\varepsilon\)-Übergang von
   \(s_1\) nach \(s_2\), und einen \(a\)-Übergang von \(s_2\) nach
   \(s_3\) (bzw. auch \(a\)-Übergang von \(s_1\) nach \(s_2\), und einen
   \(\varepsilon\)-Übergang von \(s_2\) nach \(s_3\)), dann füge einen
   Übergang \((s_1,a,s_3)\) ein; iterieren über neu hinzugefügte
   Übergänge

4. Endzustandsmenge bestimmen: Endzustände sind alle Zustände von denen
   aus \(f\) über eine Folge von \(\varepsilon\)-Übergängen erreichbar
   ist

5. alle \(\varepsilon\)-Übergänge eliminieren

Pumping-Lemma für reguläre Sprachen

- Wie kann man feststellen dass eine Sprache _nicht_ regulär ist?

- Für reguläre Sprachen \(L\) gilt das Pumping-Lemma:\\
  Sei L regulär. Dann gibt es eine natürliche Zahl n so dass
  \(\forall x \in L \textrm{ mit } |x|\geq n\) gilt:\\
  \(x\) lässt sich so in Teilworte \(u, v, w\) zerlegen, d.h. \(x=uvw\),
  dass gilt:

  1. \(|v| \geq 1\)

  2. \(|uv| \leq n\)

  3. \(uv^iw \in L\quad \forall i = 0, 1, 2, ...\) ("aufpumpen" von
     \(x\))

- Genügt \(L\) diesem Lemma nicht, dann kann \(L\) nicht regulär sein

Beispiel: \(L=\{a^kb^k\mid k\geq 1\}\)

Entscheidungsprobleme für reguläre Sprachen Seien \(G\) bzw. \(G_1\) und
\(G_2\) Typ-3 Grammatiken. Die folgenden Probleme sind algorithmisch
entscheidbar:

- Wortproblem \(w \in L(G)?\)

- Leerheitsproblem \(L(G) = \varnothing?\)

- Endlichkeitsproblem \(|L(G)|=\infty ?\)

- Schnittproblem \(L(G_1) \cap L(G_2) = \varnothing ?\)

- Äquivalenzproblem \(L(G_1) = L(G_2)?\)

Zusamenfassung

- reguläre Grammatik (\(w_1 \rightarrow w_2 \in P\))

  - \(|w_1|\leq|w_2|\) (Wort wird nicht kürzer, Typ-1)

  - \(w_1 \in V\) (\(w_1\) ist einzelne Variable, Typ-2)

  - \(w_2 \in \Sigma \cup \Sigma V\) (\(A \rightarrow a\) oder
    \(A \rightarrow aB\), Typ-3)

- DFA

- NFA

- \(\varepsilon\)FA

- reguläre Ausdrücke

- Widerspruch zum Pumping-Lemma \(\rightarrow\) Sprache _nicht_ regulär

* Kellerautomaten
:PROPERTIES:
:CUSTOM_ID: kellerautomaten
:END:

Kellerautomaten (PDA, i.Allg. nichtdeterministisch)

- Grundidee Kellerautomat (PDA, push-down automaton)

  - FA wird erweitert um einen zusätzlichen Kellerspeicher (Stack,
    Stapel) mit unbeschränkter Kapazität

  - Stack: Datenstruktur mit den Methoden pop und push (LIFO-Prinzip)

  - pop: oberstes Zeichen wird gelesen und gelöscht

  - push: neues Zeichen wird auf den Stack geschrieben

- Konfigurationsübergänge

  - Nächstes Zeichen des Eingabewortes sowie oberstes Symbol auf Stack
    werden gelesen

  - abhängig davon erfolgt Zustandsübergang, und es werden (i.Allg.
    mehrere) push-Operationen ausgeführt

  - möglich sind auch \(\varepsilon\)-Übergänge: Zustandsübergang und
    Stack- Operationen ohne Weiterlesen des Eingabewortes

Spezifikation PDA

- Spezifikation nichtdeterministischer PDA\\
  \(A_{PDA}=(S, \Sigma, \Gamma, \delta, s_0, \#, F)\)

  - \(S\): Zustandsmenge

  - \(\Sigma\): Terminalalphabet

  - \(\Gamma\): Kelleralphabet

  - \(\delta\): Zustandsüberführungsrelation,
    \(\delta \subseteq S \times \Sigma \times \Gamma \times S \times \Gamma^*\)

  - \(\#\): Kellerboden-Symbol, \(\# \in \Gamma\)

  - \(s_0\): Startzustand, \(s_0 \in S\)

  - \(F\): Menge von Endzuständen

- Konfiguration: \((s, u, \gamma)\)

- Konfigurationsübergang:
  \((s_1, av, A\beta) \mapsto (s_2, v, \alpha\beta)\)

Akzeptierte Sprache

- Akzeptanzverhalten

  - per Endzustand akzeptierte Sprache\\
    \(L(A)=\{w \in \Sigma^* \mid (s_0, w, \#) \mapsto^* (s_f, \varepsilon, \beta), s_f \in F, \beta \in \Gamma^*\}\)\\
    d.h. Keller muss nicht leer sein

  - durch leeren Keller akzeptierte Sprache\\
    (beachte: auch der Kellerboden wird gelöscht!)\\
    \(L_\varepsilon(A)=\{w \in \Sigma^*\mid (s_0, w, \#) \mapsto^* (q, \varepsilon, \varepsilon), q \in S\}\)\\
    d.h. Zustand am Wortende kann beliebig sein

- die beiden Akzeptanzbedingungen sind wie folgt äquivalent:

  - zu jedem nichtdet. PDA \(K\) gibt es einen PDA \(K'\) mit
    \(L(K) = L_\varepsilon(K')\)

  - zu jedem nichtdet. PDA \(K\) gibt es einen PDA \(K'\) mit
    \(L(K') = L_\varepsilon(K)\)

Zusammenhang mit kontextfreien Sprachen

- zu jedem PDA lässt sich eine kontextfreie Grammatik konstruieren, die
  die gleiche Sprache generiert (siehe Folie
  [[#Grammatik_aus_PDA][[Grammatik_aus_PDA]]])

- zu jeder kontextfreien Grammatik lässt sich ein (i.Allg.
  nichtdeteministischer) PDA konstruieren, der die gleiche Sprache
  akzeptiert

- Grundsätzlicher Zusammenhang mit kontextfreier Grammatik

  - PDA kann mit Grammatik-Startsymbol \(S\) als Kellerboden
    initialisiert werden

  - liegt Variable A oben auf Stack: per \(\varepsilon\)-Übergang durch
    rechte Seite einer Regel ersetzen (Produktion anwenden, dabei
    nichtdeterministisch raten)

  - liegt Terminalsymbol \(a\) oben auf Stack: mit gelesenem Symbol
    abgleichen; Löschen bei Übereinstimmung, sonst Kopie verwerfen
    (matching Kellertop mit aktuellem Eingabezeichen)

  - Äquivalenter PDA ist i.Allg. nichtdeterministisch; lässt sich
    i.Allg. _nicht_ in einen deterministischen PDA äquivalent umrechnen

Beispiel: Umwandlung Typ-2-Grammatik \(\rightarrow\) Kellerautomat
Grammatik:
\[P=\{ S\rightarrow \varepsilon \mid X, \quad X \rightarrow aXa\mid bXb \mid aa \mid bb\}\]
Kellerautomat:\\

PDA, der mit leerem Keller akzeptiert \(\rightarrow\) kontextfreie
Grammatik

Regeln

- Startregel\\
  \(S\rightarrow [s_0, \#, s_i]\) für alle \(s_i \in S\)

- Übergang \((s_j,a,A,s_k,B_1\ldots B_m)\)\\
  \([s_j,A,s_{m+1}] \rightarrow a[s_k,B_1,s_l]\ldots[s_m,B_m,s_{m+1}]\)
  für alle Kombinationen \(s_l,\ldots,s_{m+1}\)

- Übergang \((s_j,a,A,s_k,\varepsilon)\)\\
  \([s_j,A,s_k]\rightarrow a\)

Beispiel \(L=\{a^nb^n \mid n \geq 1\}\)\\
\(\delta=\{(s_0,a,\#,s_0,A),(s_0,a,A,s_0,AA),\)\\
\((s_0,b,A,s_1,\varepsilon),(s_1,b,A,s_1,\varepsilon)\}\)\\
Regeln: \(P=\{S \rightarrow [s_0,\#,s_0]|[s_0,\#,s_1],\)\\
\([s_0,\#,s_0]\rightarrow a[s_0,A,s_0],\)\\
\([s_0,\#,s_1]\rightarrow a[s_0,A,s_1],\)\\
\([s_0,A,s_0]\rightarrow a[s_0,A,s_0][s_0,A,s_0],\)\\
\([s_0,A,s_0]\rightarrow a[s_0,A,s_1][s_1,A,s_0],\)\\
\([s_0,A,s_1]\rightarrow a[s_0,A,s_0][s_0,A,s_1],\)\\
\([s_0,A,s_1]\rightarrow a[s_0,A,s_1][s_1,A,s_1],\)\\
\([s_0,A,s_1]\rightarrow b,\)\\
\([s_1,A,s_1]\rightarrow b\}\)

Berechnung: PDA, der mit leerem Keller akzeptiert \(\rightarrow\)
kontextfreie Grammatik

|         | a |         | a |         | b |         | b |         |  |  |  |  |
|---------+---+---------+---+---------+---+---------+---+---------+--+--+--+--|
|         |   |         |   | A       |   |         |   |         |  |  |  |  |
| ​#       |   | A       |   | A       |   | A       |   |         |  |  |  |  |
| \(s_0\) |   | \(s_0\) |   | \(s_0\) |   | \(s_1\) |   | \(s_1\) |  |  |  |  |

- Kodierung von "Aufgaben"

- Hauptaufgabe: Keller soll leer werden\\
  Starten in \(s_0\), # soll "abgebaut" werden, Folgezustand ist egal:
  \([s_0, \#, s_0]\) bzw. \([s_0, \#, s_1]\)

- Kodierungen werden als Nichtterminalsymbole (aka Variablen)
  interpretiert\\
  Startregeln: \(S \rightarrow [s_0, \#, s_0]|[s_0, \#, s_1]\)

- analog Kodierung aller weiteren Übergänge des Automaten als Regeln,
  z.B. führt das Lesen eines \(b\) im Zustand \(s_0\) zum Abbau eines
  \(A\) auf dem Stack und Übergang in \(s_1\):\\
  \([s_0, A, s_1] \rightarrow b\)

Deterministische Kellerautomaten (DPDA): Problemstellung

- Für praktische Anwendungen (Parser) wird ein im wesentlichen lineares
  Laufzeitverhalten angestrebt

- Die Simulation nichtdeterministischer Automaten zeigt i.Allg. ein
  exponentielles Verhalten

- Lässt sich jeder nichtdet. Kellerautomat in einen äquivalenten det.
  Kellerautomaten umschreiben?\\
  _nein:_ z.B. \(L=\{w\tilde{w} \mid w\in \Sigma^*\}\) ist kontextfrei,
  aber nicht durch det. PDA akzeptierbar

- _Deterministisch kontextfreie Sprachen_ sind solche, die durch einen
  deterministischen Kellerautomaten (per Endzustand) akzeptiert werden.
  Sie bilden damit eine _Unterklasse_ der kontextfreien Sprachen.

Deterministische Kellerautomaten

- Spezifikation:\\
  deterministische Zustandsüberführungsfunktion;
  _\(\varepsilon\)-Übergänge erlaubt_\\
  insoweit gilt (für \(a \in \Sigma, A \in \Gamma\)):
  \(|\delta(s, a, A)| + |\delta(s, \varepsilon, A)| \leq 1\) (d.h.: für
  jede Konfiguration \((s, ax, A\rho)\) gibt es höchstens eine
  Folgekonfiguration)

- Nichtäquivalenz von Akzeptanz per leerem Keller bzw. Endzustand bei
  det. PDA:\\
  führt bei DPDA _nicht_ zur gleichen Sprachklasse

- Definition: Präfixeigenschaft\\
  Die Sprache \(L\) hat die Präfixeigenschaft gdw. für alle \(w \in L\)
  gilt:\\
  Ist \(x\) echtes Präfix von \(w\) (d.h. \(w=xy, y \neq \varepsilon\))
  dann gilt \(x \notin L\)

- Es gilt: deterministisch kontextfreie Sprachen, die durch DPDA per
  leerem Keller akzeptiert werden können, sind genau die mit
  Präfixeigenschaft

Beziehungen zwischen Sprachklassen

- Die det. kontextfreien Sprachen \(L_\varepsilon(A)\) (mit
  Präfixeigenschaft, Akzeptanz per leerem Keller) sind echt in den det.
  kontextfreien Sprachen \(L(A)\) (Akzeptanz per Endzustand) enthalten

- _reguläre_ Sprachen sind echt in den det. kontextfreien Sprachen
  enthalten ( FA ist "Kellerautomat ohne Keller")

- es gibt _reguläre_ Sprachen, die die Präfixeigenschaft nicht besitzen
  und damit in \(L_\varepsilon(A)\) nicht enthalten sind (z.B.
  \(\alpha=a|ab\))

- es gibt _reguläre_ Sprachen, die die Präfixeigenschaft besitzen und
  damit in \(L_\varepsilon(A)\) liegen (z.B. \(\alpha=a|ba\))

- es gibt Sprachen in \(L_\varepsilon(A)\), die nicht regulär sind (z.B
  \({a^nb^n}\))

Exkurs: (N)FA im RL Pac-Man [fn:3]

[[file:images/Pac-Man.png]]

Exkurs: PDA im RL Drehkreuz

#+begin_center
[[file:images/turnstile.png]]

#+end_center

* Kontextfreie Sprachen
:PROPERTIES:
:CUSTOM_ID: kontextfreie-sprachen
:END:

Typ-2 Grammatiken: Normalformen

- Vereinfachungen für kontextfreie Grammatiken \(G\)

  - \(\varepsilon\)-Regeln eliminieren:
    \(S \rightarrow aAb; A \rightarrow aS|\varepsilon\)\\
    wird zu \(S \rightarrow aAb|ab; A \rightarrow aS\)

  - \(G\) reduzieren: nutzlose Variablen eliminieren

  - Kettenregeln \(A \rightarrow B\) entfernen

- Chomsky-Normalform

  - zu jeder \(\varepsilon\)-freien, reduzierten kontextfreien Grammatik
    \(G\) ohne Kettenregeln lässt sich eine äquivalente Grammatik \(G'\)
    angeben, die nur Regeln der Art \(A \rightarrow a\) bzw.
    \(A \rightarrow BC\) enthält.

  - Konstuktion: Ausgangspunkt
    \(A\rightarrow X_1X_2 \ldots X_m, m\geq 2, X_i \in V \cup \Sigma\)

    - für \(X_i=a\in \Sigma\) neue Variable \(X_a\) mit
      \(X_a \rightarrow a\) einführen

    - verbleibende Regeln
      \(A \rightarrow B_1B_2\ldots B_m, B_i \in V, m\geq 3\):\\
      ersetze
      \(A \rightarrow B_1D_1, D_1\rightarrow B_2D_2, \ldots, D_{m-2}\rightarrow B_{m-1}B_m\)
      (\(D_i\) neue Variablen)

- Greibach-Normalform: Regeln vom Typ
  \(A \rightarrow aB_1B_2 \ldots B_m|a\)

Beispiel: Erzeugung Chomsky-Normalform
\(G=(\{S, A, B, C, D, E\}, \{a, b\}, P, S)\)\\
\(P=\{\)\\
\(S \rightarrow bA \mid aB \mid C \mid Cb,\)\\
\(A \rightarrow bAA \mid aS \mid a \mid bE \mid bDb,\)\\
\(B \rightarrow aBB \mid bS \mid b,\)\\
\(C \rightarrow Cc \mid c,\)\\
\(D \rightarrow d \mid \varepsilon\)\\
\(\}\)

Worterkennung: Cocke-Younger-Kasami-Algorithmus (CYK) polynomiell auch
für nichtdeterministische Sprachen

- Ziel: Worterkennung und Konstruktion Ableitungsbaum bottom-up

- Ausgangspunkt: \(G\) in Chomsky-Normalform,
  \(w=a_1a_2 \ldots a_n \in \Sigma^*\)

- definiere
  \(V[i,j]:=\{A \in V \mid A \underset{G}{\Rightarrow}^* w_{ij} \}\)
  mit\\
  \(w_{ij}=a_ia_{i+1}\ldots a_{i+j-1}, |w_{ij}|=j, 1\leq i \leq n, 1\leq j \leq n+1-i\)

- es gilt: \(w\in L\) gdw. \(S \in V[1,n]\)

- schrittweise Berechnung (Rückführung auf kürzere Teilworte)\\
  \(j=1: V[i,1]=\{X \in V \mid (X\rightarrow a_i) \in P\}\)\\
  \(j>1: V[i,j]=\bigcup_{l=1}^{j-1}\{A\in V\mid \exists (A\rightarrow BC): B \in V[i,l] \land C \in V[i+l, j-l] \}\)

- Wortproblem mit polynomiellem Zeitaufwand \(O(n^3)\) lösbar

- Grammatik ist mehrdeutig, falls ein \(V[i,j]\) mehrere Einträge hat,
  die von \(S\) aus erreicht werden können

Beispiel: CYK-Algorithmus \[L=\{a^nb^n\mid n\geq 1\}\] Zugehörige
Grammatik in Chomsky-Normalform: \[\begin{aligned}
		G=(&\{A, B, C, S\}, \{a, b\}, P, S)\\
		P=\{&S \rightarrow AB,\\
		    &S \rightarrow AC,\\
		    &C\rightarrow SB,\\
		    &A\rightarrow a,\\
		    &B\rightarrow b\}
	
\end{aligned}\]

Pumping-Lemma für kontextfreie Sprachen

- Pumping-Lemma: für jede kontextfreie Sprache \(L\) gilt\\
  es existiert eine natürliche Zahl \(n\) so, dass für alle \(z \in L\)
  mit \(|z|\geq n\) gilt:\\
  \(z\) lässt sich zerlegen in \(z=uvwxy\) mit

  - \(|vx|\geq 1\)

  - \(|vwx| \leq n\)

  - \(uv^iwx^iy \in L, i=0, 1, 2, \ldots\)

- Beweis:

  - wähle \(n=2^m\), \(m\): Anzahl der Nichtterminalsymbole, wenn sich G
    in Chomsky-Normalform befindet

  - mindestens eine Variable \(A\) muss sich im Ableitungsbaum nach
    spätestens \(m\) Schritten wiederholen;\\
    \(A\underset{G}{\Rightarrow}^*\omega_1 A \omega_2\), wähle
    \(v: \omega_1 \underset{G}{\Rightarrow}^* v, x: \omega_2 \underset{G}{\Rightarrow}^* x, w: A \underset{G}{\Rightarrow}^* w\);\\
    diese Ableitungen enthalten jeweils keine Wiederholungen von
    Variablen

Beispiel: Pumping-Lemma für kontextfreie Sprachen
\(L=\{a^ib^ic^i \mid i\geq 1 \}\)

- \(L\) ist kontext-sensitiv: Beweis Typ-1-Grammatik\\
  \(G=(V, \Sigma, P, S), V=\{S, B, C\}\)\\
  \(P=\{S\rightarrow aSBC | aBC, CB \rightarrow BC,\)\\
  \(aB \rightarrow ab, bB \rightarrow bb, bC \rightarrow bc, cC \rightarrow cc \}\)

- \(L\) ist nicht kontextfrei: Beweis Pumping-Lemma\\
  wäre \(L\) kontextfrei, sei \(n\) das "Pumping-\(n\)"\\
  wähle \(z=a^nb^nc^n \in L, |z|=3n \geq n\)\\
  es ex. eine Zerlegung \(z=uvwxy\) mit \(|vx|\geq 1, |vwx| \leq n\)\\
  \(\rightarrow\) \(vwx\) kann höchstens zwei verschiedene Buchstaben
  enthalten\\
  \(\rightarrow\) in \(uv^iwx^iy\) werden ein oder zwei Buchstaben
  "aufgepumpt", der dritte nicht\\
  \(\rightarrow\) \(uv^iwx^iy \notin L\) für \(i \neq 1\)

Abschlusseigenschaften kontextfreier Sprachen

- Kontextfreie Sprachen sind abgeschlossen unter

  - Vereinigung: \(L_1\cup L_2\)\(S \rightarrow S_1|S_2\)

  - Konkatenation: \(L_1L_2\) \(S\rightarrow S_1S_2\)

  - Stern-Produkt: \(L^*\)
    \(S_0\rightarrow S|\varepsilon, S\rightarrow S_1|S_1S\)

  - Spiegelung: ersetze in Chomsky-Normalform \(A\rightarrow BC\) durch
    \(A \rightarrow CB\)

- Kontextfreie Sprachen sind _nicht_ abgeschlossen unter

  - Durchschnitt\\
    Gegenbeispiel:
    \(L_1=\{a^kb^kc^l\mid k,l\geq 0\}, L_2=\{a^kb^lc^l\mid k,l\geq 0\}\)
    sind kontextfrei\\
    \(L=L_1\cap L_2\) ist nicht kontextfrei

  - Komplement\\
    \(L_1 \cap L_2 = \overline{\overline{L_1} \cup \overline{L_2}}\):
    Abgeschlossenheit unter Vereinigung und Komplement würde zu
    Abgeschlossenheit unter Durchschnitt führen\\
    \(\rightarrow\) Widerspruch zu a)

Abschlusseigenschaften deterministisch kontextfreier Sprachen

1) Deterministisch kontextfreie Sprachen sind abgeschlossen unter
   Komplementbildung (beachte: Akzeptanz durch Endzustand!)

2) Deterministisch kontextfreie Sprachen sind _nicht_ abgeschlossen
   unter

   1. Durchschnitt \(L_1 \cap L_2\)

   2. Konkatenation \(L_1L_2\)

   3. Stern-Produkt \(L^*\)

   4. Vereinigung \(L_1 \cup L_2\)

3) \(L_1 \cap L_2\) ist allerdings det. kontextfrei (bzw. kontextfrei)
   falls \(L_1\) regulär und \(L_2\) det. kontextfrei (bzw. kontextfrei)
   ist

* Typ-0-Sprachen und Turing-Maschinen
:PROPERTIES:
:CUSTOM_ID: typ-0-sprachen-und-turing-maschinen
:END:

Wortproblem

- Wortproblem für Typ-0- bzw. Typ-1-Sprachen

  - Wortproblem: gegeben: \(w \in \Sigma^*\), Grammatik \(G\);
    \(w \in L(G)?\)

  - Entscheidbarkeit des Wortproblems \(w \in L\)

    - \(L\) heißt entscheidbar gdw. es existiert ein Algorithmus, der
      für jedes \(w \in \Sigma^*\) nach endlich vielen Schritten hält
      und die Antwort "ja" bzw. "nein" liefert

    - \(L\) heißt semi-entscheidbar gdw. ex existiert ein Algorithmus,
      der für jedes \(w \in L\) nach endlich vielen Schritten mit
      Antwort "ja" hält, für \(w \notin L\) aber kein definiertes
      Antwortverhalten hat (z.B. gar nicht hält)

  - es gilt

    - Das Wortproblem für Typ-1-Sprachen ist entscheidbar

    - das Wortproblem für Typ-0-Sprachen ist semi-entscheidbar

- akzeptierender Automat für Typ-0-Sprachen: Turing-Maschine\\
  (bzw. Linear beschränkter Automat (LBA) als Spezialfall für
  Typ-1-Sprachen)

Exkurs: Abzählbarkeit von Mengen

- Mächtigkeit unendlicher Mengen A, B:

  - \(|A|\leq |B|\) gdw. es gibt eine injektive Abbildung
    \(f: A \rightarrow B\)

  - \(|A| = |B|\) gdw. \(|A|\leq |B|\) und \(|B|\leq |A|\), d.h. es
    existiert eine bijektive Abbildung zwischen \(A\) und \(B\)

- \(A\) heißt abzählbar gdw. \(A\) ist endlich, oder
  \(|A|=|\mathbb{N}|\), d.h. \(A\) lässt sich bijektiv auf
  \(\mathbb{N}\) oder eine Teilmenge von \(\mathbb{N}\) abbilden

- Die Menge aller geordneten Paare natürlicher Zahlen
  \(\{(n,m)\mid n, m \in \mathbb{N}\}\) ist abzählbar

- es gilt: sei \(\Sigma\) endliches Alphabet, dann ist \(\Sigma^*\)
  abzählbar

- Folgerung: die Menge aller Algorithmen (Programm = Wort über einem
  endlichen Alphabet (z.B. binär)) ist abzählbar

- Die Menge aller Sprachen über \(\Sigma^*\) (d.h.
  \(\mathcal{P}(\Sigma^*)\)) ist überabzählbar

- Folgerung: /es gibt offensichtlich unentscheidbare Sprachen/

Semi-entscheidbare und rekursiv aufzählbare Sprachen

- es gilt: \(L\) ist entscheidbar gdw. \(L\) und \(\overline{L}\) sind
  semi-entscheidbar

- Def: eine Sprache \(L\) heißt _rekursiv aufzählbar_ gdw. es gibt eine
  berechenbare surjektive Funktion \(f: \mathbb{N} \rightarrow L\), d.h.
  es gilt \(L=\{f(1), f(2), \ldots\}\)

- Entscheidbare Sprachen werden alternativ auch als _rekursive_ Sprachen
  bezeichnet

- es gilt: \(L\) ist rekursiv aufzählbar gdw. \(L\) ist
  semi-entscheidbar

- es gilt: \(L\) rekursiv aufzählbar \(\rightarrow\) \(L\) abzählbar;
  die Umkehrung gilt nicht

- es gilt: die Typ-0-Sprachen sind genau die rekursiv aufzählbaren
  Sprachen

Nichtdeterministische Turing-Maschinen

- TM "Hardware" (Basismodell 1-Band-TM):

  - Speicherband (unbeschränkt, oder halbseitig beschränkt); jede
    Speicherzelle kann ein Zeichen aus dem Bandalphabet aufnehmen

  - Lese-Schreib-Kopf: kann aktuelles Zeichen lesen und überschreiben;
    bewegt sich danach einen Schritt nach links oder rechts (L/R) oder
    bleibt stehen (N)

- Spezifikation TM: \(M=(S, \Sigma, \Gamma, \delta, s_0, \#, F)\)

  - Zustandsmenge

  - Terminalalphabet

  - Bandalphabet, \(\Sigma \subset \Gamma\)

  - Zustandsüberführungsrelation;
    \(\delta \subseteq S \times \Gamma \times S \times \Gamma \times \{L, R, N\}\)

  - Startzustand, \(s_0 \in S\)

  - Blank-Symbol (Leerzeichen), \(\# \in \Gamma \setminus \Sigma\)

  - Menge von Endzuständen, \(F \subseteq S\)

Konfigurationsübergänge, Akzeptanzverhalten

- Konfiguration:\\
  \((s, u\underline{\alpha}v)\): Zustand \(s\), Bandinhalt
  \(u\alpha v\), Kopf unter \(\alpha \in \Gamma\), \(u,v \in \Gamma^*\)

- Konfigurationsübergänge: \(\alpha, \beta, \rho, \omega \in \Gamma\),
  \(u, v \in \Gamma^*\)

  - \((s_1, \alpha, s_2, \beta, R) \in \delta:\)\((s_1, u\rho\underline{\alpha}\omega v) \mapsto (s_2, u\rho\beta\underline{\omega}v)\)

  - \((s_1, \alpha, s_2, \beta, L) \in \delta:\)\((s_1, u\rho\underline{\alpha}\omega v) \mapsto (s_2, u\underline{\rho}\beta\omega v)\)

  - \((s_1, \alpha, s_2, \beta, N) \in \delta:\)\((s_1, u\rho\underline{\alpha}\omega v) \mapsto (s_2, u\rho\underline{\beta}\omega v)\)

- Initialisierung:\\
  Bandinhalt: \(\#\#\# w\#\#\#\ldots\), Kopf unter erstem Buchstaben von
  \(w\)

- TM akzeptiert \(w\) (als Element von \(L\)), gdw. es existiert eine
  Folge von Konfigurationsübergängen, so dass TM in einem Endzustand
  hält

  - "TM hält" bedeutet: in der jeweiligen Konfiguration gibt es keinen
    Folgeübergang

Varianten von TM

- Ein-Band-TM\\
  linksbeschränktes Band; unbeschränktes Band; Mehrspur-TM: LS-Köpfe
  fest verbunden

- Mehr-Band-TM\\
  \(\delta(s, \{\sigma_1, \ldots, \sigma_k\}) = (s', \{\sigma_1', \ldots, \sigma_k'\},\{r_1,\ldots,r_k\})\)\\
  \(\sigma_i \in \Gamma, \sigma_j' \in \Gamma, r_m \in \{L, R, N\}\),
  d.h. LS-Köpfe einzeln frei beweglich

- Alle Varianten können sich gegenseitig simulieren und sind damit
  gleich mächtig

- Bemerkung: Codierung Bandinhalt\\
  natürliche Zahl \(n \rightarrow |^n\) (unäre Darstellung,
  "Bierdeckelnotation"), oder Binärdarstellung

TM: Beispiel \[L=\{a^nb^n \mid n\geq 0\}\] \[\begin{aligned}
		\delta = \{&(s_0, a, s_1, x, R), (s_0, x, s_0, x, R), (s_0, \#, s_f, \#, N),\\
		&(s_1, x, s_1, x, R), (s_1, a, s_1, a, R), (s_1, b, s_2, x, R),\\
		&(s_2, b, s_2, b, R), (s_2, \#, s_3, \#, L), (s_3, b, s_3, b, L),\\
		&(s_3, x, s_3, x, L), (s_3, a, s_3, a, L), (s_3, \#, s_0, \#, R)\}
	
\end{aligned}\] Arbeitsweise

- erstes verbliebenes \(a\) wird durch Füllzeichen \(x\) überschrieben

- erstes verbliebenes \(b\) wird durch Füllzeichen \(x\) überschrieben

- stellt sicher, dass bis zum Wortende nur \(b\)'s kommen

- zurück zum Wortanfang

- falls \(w\in L\): am Schluss stehen nur noch \(x\) auf dem Band;
  Übergang in akzeptierenden Zustand \(s_f\)

Linear beschränkte Automaten (LBA) und kontextsensitive Sprachen

- LBA: TM, die den Bandbereich auf dem die Eingabe steht niemals
  verlässt (in-place)

- es gilt (Satz von Kuroda): die von einem (nichtdeterministischem) LBA
  akzeptierten Sprachen sind die kontextsensitiven Sprachen (Typ-1).\\
  Beweisidee:

  - Sei \(L\) Typ-1; \((u \rightarrow v) \in P, |u|\leq |v|\);\\
    LBA: ersetzt (nichtdet.) Teilwort \(v\) durch Teilwort \(u\);
    überschreitet dabei Bandbegrenzung nicht; \(w\) kann dabei auf \(S\)
    reduziert werden, falls \(w \in L\)

  - sei \(M\) LBA, der \(L\) akzeptiert;\\
    \(G\): bilde Variablen \((s, c)\) mit \(c \in \Gamma\);\\
    \(P\): sei z.B. \((s_1, a, s_2, b, L) \in \delta\),
    korrespondierende Typ-1-Regel in \(P\):
    \(c(s_1, a) \rightarrow (s_2, c)b\) für alle \(c \in \Gamma\)

Turingmaschinen und Typ-0-Sprachen

- es gilt: die durch allgemeine TM akzeptierten Sprachen sind genau die
  Typ-0-Sprachen\\
  Beweis analog zu kontextsensitiven Sprachen unter Verzicht auf lineare
  Beschränktheit des Automaten bzw. Typ-1 Bedingung für Grammatik

- Abgeschlossenheit

  - Sowohl Typ-0-Sprachen wie auch speziell die Typ-1-Sprachen sind
    abgeschlossen unter Durchschnitt, Vereinigung, Konkatenation und
    Stern-Produkt

  - Typ-1-Sprachen _sind_ abgeschlossen unter Komplement

  - Typ-0-Sprachen _sind nicht_ abgeschlossen unter Komplement

eine entscheidbare Sprache, die nicht in \(L_1\) liegt

- Worte \(w \in \Sigma^*\) sind aufzählbar: \(w_1, w_2, \ldots\)\\
  Damit kann jedem Wort eineindeutig eine Nummer \(i\) zugeordnet werden

- Typ-1- (wie auch Typ-0-) Grammatiken sind Worte über einem erweiterten
  Alphabet \(\Gamma = V \cup \Sigma \cup \{\rightarrow, ;\}\) und sind
  ebenfalls aufzählbar: \(G_1, G_2, \ldots\)\\
  Damit existiert eine bijektive Abbildung \(f(w_i) = G_i (= G_{w_i})\)

- Definiere \(L_D=\{w \in \Sigma^* \mid w \notin L(G_w)\}\)\\
  es gilt:

  - \(L_D\) ist nicht Typ-1

  - \(L_D\) ist entscheidbar

Sprachklassen: Zusammenfassung und Ausblick

[[file:images/Sprachklassen_Typ0_Typ1.pdf]]

- Typ-1-Sprachen sind entscheidbar

- es gibt entscheidbare Sprachen, die Typ-0 aber nicht Typ-1 sind (z.B.
  \(L_D\))

- es gibt Typ-0-Sprachen, die nicht entscheidbar sind (z.B. \(L_H\))

- es gibt Sprachen, die nicht Typ-0 sind, d.h. nicht durch eine
  Grammatik erzeugt werden können (z.B. \(\overline{L_H}\))

Alan Mathison Turing (, )

- englischer Mathematiker, Logiker, Kryptoanalytiker, Informatiker

- Erfinder der Turingmaschine

- Mitbegründer der Theoretischen Informatik

- Entwickler des Turing-Tests

- Knackte die Enigma-Verschlüsselung im Zweiten Weltkrieg

- Schriften:

  - /On Computable Numbers, with an Application to the
    Entscheidungsproblem/ (1936)

[[file:images/Alan_Turing_(1951)_(crop).jpg]][fn:4]

* Abschluss
:PROPERTIES:
:CUSTOM_ID: abschluss
:END:

Empfehlung: JUG Saxony Day [[file:images/JSD-Logo_gruen.png]]

- September in Radebeul

- Freitickets für Studis

- Großartige Vorträge zu verschiedensten Themen

- Lecker Omnomnom

- [[https://jugsaxony.org/day]]

Kontakt

- [[https://www.linkedin.com/in/peter-kossek-851b90195][linkedin.com/in/peter-kossek-851b90195]]

- [[https://www.xing.com/profile/Peter_Kossek2][xing.com/profile/Peter_Kossek2]]

- [[https://t.me/squinting_cyclops][=@squinting_cyclops=]]

- [[https://www.instagram.com/squinting.cyclops][=@squinting.cyclops=]]

[fn:1] [[https://commons.wikimedia.org/wiki/File:George_Boole_color.jpg]]

[fn:2] [[https://commons.wikimedia.org/wiki/File:Noam_Chomsky_portrait_2017_retouched.jpg]]

[fn:3] Applications of Deterministic Finite Automata, Eric Gribkoff,
       [[https://www.cs.ucdavis.edu/~rogaway/classes/120/spring13/eric-dfa.pdf]]

[fn:4] [[https://commons.wikimedia.org/wiki/File:Alan_Turing_(1951)_(crop).jpg]]
